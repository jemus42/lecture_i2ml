l
# Tuning

## Find best hyperparameters

## Grid Search

## Random Search

## Example with grid search

# Imputation

# Feature engineering

## Correct coding of variables
Factors, Numerical,  how to deal with texts

## Scaling and transforming  numerical features
- log, sqrt for skewed features
- Standardize TODO formula
- Normalize TODO formula


## Text features


## Creating features in a resampling setup
- Feature engineering is part of your pipeline
- Assume you don't have access to your test data
- Example: Feature mean centering
  - Don't use the test data in estimating the feature means
  - Do use only the training data mean for centering the test data features

# Do's and don'ts

## Do explore your data using plots
- Univariate boxplots, barcharts, ...
- Subsample if dataset is large
- Coding speed > visualization perfection

## Do check for outliers
Could be mistakes in the dataset

## Dont code categorical variables as numbers
EXAMPLE with R
Information gets lost
Pseudo order introduced

## Do code categorical variables appropriately
R automatically creates dummy matrix

## Do make your work reproducible
- Meaningful folder structure, e.g.
  - Folders data, figures, code, text
- All code in scripts that run end to end from data reading to prediction.
- Don't have interactive steps in final result.
- Use version control (git)
- Set a seed. Important for any step that requires sampling or some other mechanism of randomness
- Save intermediate

## Don't dive into the predictive modeling task without preparation
- Identify the error measure to optimize
- Split data into train and test set, or use other resampling technique
- Use only training data for creating new features.


# Case study

# Kaggle
Machine Learning competition platform

# Predict property sale prices
- Create account
- Join competition: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

#
Do Kaggle competition

https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data
