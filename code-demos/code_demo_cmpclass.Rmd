---
output: pdf_document
params:
  set_title: "Code demo for comparission of classification methods"
---
  
```{r cmpclass-preamble, child = "../style/preamble_code_demos.Rmd", include = FALSE, purl = FALSE}

```

```{r cmpclass-setup, child = "../style/setup.Rmd", include = FALSE, purl = FALSE}

```  

```{r knn-load_chunk, echo=FALSE, cache=FALSE, purl=FALSE}
# see https://stackoverflow.com/a/28151571
run_chunks <- function(chunkNames, envir = .GlobalEnv) {
  for(chunkName in chunkNames){
    chunkName <- unlist(lapply(as.list(substitute(.(chunkName)))[-1], as.character))
    eval(parse(text = knitr:::knit_code$get(chunkName)), envir = envir)
  }
}

load_chunks <- function(rmd_files){
  for(rmd_file in rmd_files){
    knitr::purl(paste0(rmd_file,".Rmd"), paste0(rmd_file,".R"), documentation=2)
    knitr::read_chunk(paste0(rmd_file,".R"))
  }
}

load_chunks(c("code_demo_genclass","code_demo_knn"))
run_chunks(c("knn-plot_2D_classif", 
             "genclass-nb_priors",
             "genclass-nb_lhoods",
             "genclass-naivebayes",
             "genclass-classify_naivebayes",
             "genclass-plot_2D_naivebayes",
             "genclass-nb_kde"
             ))
```

# Code demo for comparission of classification methods

## Softmax

Generalization of the logistic function

## Data

```{r cmpclass-data}
library(mlbench)
library(mlr)
library(ggplot2)

set.seed(123L)

spirals <- data.frame(mlbench.spirals(n = 500, sd = 0.1))
ggplot(spirals, aes(x.1,x.2, color=classes)) + geom_point()

cassini <- data.frame(mlbench.cassini(500))
ggplot(cassini, aes(x.1,x.2, color=classes)) + geom_point()

simplex <- data.frame(mlbench.simplex(n = 500, d=2))
ggplot(simplex, aes(x.1,x.2, color=classes)) + geom_point()

```
```{r cmpclass-task}

spirals_task = makeClassifTask(data = spirals, target = "classes")
cassini_task = makeClassifTask(data = cassini, target = "classes")
simplex_task = makeClassifTask(data = simplex, target = "classes")
```

```{r cmpclass-learners}
learners <- list(
softmax_learner = makeLearner("classif.multinom", trace=FALSE),
softmax_knn = makeLearner("classif.knn"),
lda_learner = makeLearner("classif.lda"),
qda_learner = makeLearner("classif.qda"),
nb_learner = makeLearner("classif.naiveBayes")
)
```

## Comparision


```{r cmpclass-cassini, fig.height=12, fig.width=12}
library(gridExtra)

ggplot_list <- lapply(
  learners,
  function(learner) plotLearnerPrediction(learner, cassini_task)
)
do.call(grid.arrange, ggplot_list)
```

```{r cmpclass-simplex, fig.height=12, fig.width=12}
ggplot_list <- lapply(
  learners,
  function(learner) plotLearnerPrediction(learner, simplex_task)
)
do.call(grid.arrange, ggplot_list)
```

```{r cmpclass-spirals, fig.height=12, fig.width=12}
ggplot_list <- lapply(
  learners,
  function(learner) plotLearnerPrediction(learner, spirals_task)
)
do.call(grid.arrange, ggplot_list)
```

```{r cmpclass-test}
library("kdensity")
library("EQL")

features <- c("x.1","x.2")
target <- "classes"
X <- spirals[, features]
liks_kde <- get_naivebayes_likelihoods(
  spirals, target,
  sapply(features, function(feature)
    list(
      args = list(),
      features = feature,
      type = "kde"
    ),
  simplify = FALSE,
  USE.NAMES = TRUE
  )
)


priors <- get_priors(spirals, target)

plot_2D_naivebayes(priors, liks_kde, "x.1", "x.2",
      spirals$classes, X,
      title = '"NB" ~'
)
```