---
output: pdf_document
params:
  set_title: Code demo for Splines
---

```{r, child = "../style/preamble_code_demos.Rmd", include = FALSE}
```

```{r, child = "../style/setup.Rmd", include = FALSE}
```  



# Splines

## Basic idea  

- One common idea in machine learning consists in transforming the features of interest.
- Here we will take a look on so-called splines.
- With splines we can model arbitrarily well smooth functional relationships.
- This means that we will represent the features as projections on a splines basis.
- We can treat this projected features *like we did for the linear model* and by using the empirical risk minimization we can get then an estimation for the regression coefficients, which determine the shape of the spline.

## B-splines

- One of the most common used spline basis is the so-called B-spline basis, which consists of locally defined polynomials.
- To use splines we have to fill our domain with knots $t_0,\dots,t_{m+1}$, which will serve as supporting points for the spline.
- For example we can use 5 equidistant knots with a piecewise polynomial degree
$l = 1$:
```{r, echo=FALSE}
library(splines)
library(reshape2) 
 
bs_plot <- function(poly_deg = 1, num_bfuns = 3, min, max) {
  num_data = 1000

  x = seq(min, max, length.out = num_data)

  bbasis = bs(x, df=num_bfuns, degree = poly_deg, intercept = T)

  plot_data = melt(data.frame(cbind(bbasis, x)), id = "x")

  ggplot(plot_data, aes(x = x, color = variable)) +
    geom_line(aes(y = value),size=2) + xlim(min, max) +
    ylab("y") + theme(legend.position = "none") + scale_color_brewer(palette ="Set3") + labs(title=paste("Piecewise polynomial degree:",as.character(poly_deg)))
}

 example_xmin = -3
 example_xmax = 3
 examplepoly_deg = 1
 example_num_bfuns = 5
 bs_plot(poly_deg = examplepoly_deg, num_bfuns = example_num_bfuns, example_xmin,
  example_xmax)
```

- For the number of basis function $K$ it holds that
$$K = m+l+1$$.
- This means from our machine learning perspective we are projecting the feature $x$ into a $(3+1+1=5)$-dimensional vector space in our little example, s.t. it holds e.g. for $x = 0.3$

```{r, echo=FALSE}
library(splines)
library(reshape2)
x = 0.3 
  xs = seq(example_xmin,example_xmax, by=0.1)
 bs_plot(poly_deg = examplepoly_deg, num_bfuns = example_num_bfuns, example_xmin,
  example_xmax) + geom_vline(xintercept = x, size=1.5,
 linetype="dashed")
  print(paste0("y = (",paste( (bs(x = xs, df=example_num_bfuns, degree = examplepoly_deg, intercept = T,
  Boundary.knots = c(example_xmin, example_xmax))[which(xs >= x)[1],]),
  collapse=", "),")."))
```


## Example
Let's look at real data, where we want to model a functional relationship:
```{r}
library(mlbench)
library(ggplot2)
library(splines)

data(BostonHousing2)

(medv_rooms_plot = ggplot() +
  geom_point(data=BostonHousing2,aes(x = rm, y = medv), alpha = 0.3) +
  labs(   x = "Average number of rooms",
       y = "Median value"))
```

Now let's say we want to use 5 piecewise polynomials of degree 2:
```{r}

poly_deg = 2
num_bfuns = 5
num_data = 1000 # number of points we want to use for plotting

rm_min = min(BostonHousing2$rm)
rm_max = max(BostonHousing2$rm)

rooms = seq(rm_min, rm_max, length.out = num_data)

bbasis_plot = bs(rooms, df= num_bfuns ,degree = poly_deg, intercept=TRUE)
plot_data = melt(data.frame(cbind(bbasis_plot, rooms)), id = "rooms")

medv_rooms_plot + geom_line(data=plot_data, aes(x=rooms, y = value, color=variable)) +  theme(legend.position = "none")
```

Train a linear model but for the transformed features:

```{r}
# since we want to use the same transformation, we have to specify the knots and piecewiese polynomial degree, we have used before
bbasis_data = data.frame(bs(x=BostonHousing2$rm,Boundary.knots = attr(bbasis_plot,"Boundary.knots"),
  knots=attr(bbasis_plot,"knots"), degree = poly_deg, intercept=TRUE)
  )
bbasis_data$medv = BostonHousing2$medv

# estimate a linear model for transformed features and exclude the intercept term  as it has already been included in the b-splines basis functions
lm_bs = lm(medv ~ . -1, data = bbasis_data)

# use the solution of the linear model to scale the features
for(i in 1:ncol(bbasis_plot)){ bbasis_plot[,i] = bbasis_plot[,i]*
  lm_bs$coefficients[i] }

  plot_data = melt(data.frame(cbind(bbasis_plot, rooms)), id = "rooms")

  medv_rooms_plot + geom_line(data=plot_data, aes(x=rooms, y = value, color=variable)) +  theme(legend.position = "none")

```

We can get our estimate for the functional relationship simply by summing the scaled features:

```{r}
function_estimate = data.frame(x = rooms)

function_estimate$y = rowSums(bbasis_plot)

    medv_rooms_plot + geom_line(data=function_estimate, aes(x=rooms, y = y)) +  theme(legend.position = "none")
```
 Wrap these steps up in one plot function:
```{r bspline}

plot_bs_fit <- function(poly_deg, num_bfuns) {
  num_data = 1000
  bspline = bs(BostonHousing2$rm,df = num_bfuns,degree = poly_deg, intercept = TRUE
  )
  bspline_data =  data.frame(bspline)
  bspline_data$medv = BostonHousing2$medv
  # estimate a linear model for transformed features (without intercept)
  lm_bs = lm("medv ~ . -1", data = bspline_data)

  plot_data = data.frame(x = seq(min(BostonHousing2$rm),max(BostonHousing2$rm), length.out = num_data))
  # scale and add up (i.e. use matrix product)
  plot_data$y = bs(plot_data$x, knots = attr(bspline,"knots"), degree = poly_deg,
      Boundary.knots = attr(bspline,"Boundary.knots"), intercept=TRUE
  ) %*%
    lm_bs$coefficients
  ggplot() +
    geom_point(data=BostonHousing2,aes(x=rm, y = medv), alpha = 0.3) +
    geom_line(data = plot_data, aes(x = x, y = y), color="red") +
    labs(title = paste(as.character(num_bfuns), "basis function(s)"),
         x = "Average number of rooms",
         y = "Median value")
}

```

Vary number of basis functions for piecewiese cubic splines:
```{r}
library(ggplot2)
library(gridExtra)

poly_deg = 3
num_bfuns = c(1, 5, 15, 50)
ggplot_list = lapply(num_bfuns, function(x) plot_bs_fit(poly_deg,x))
do.call(grid.arrange, ggplot_list)
```

- We only computed a simple linear model, but instead of the original feature we used its transformed features.
- We observe that the quality of the fit depends on the number of basis functions/knots that we choose.
- For higher number of basis functions/knots a phenomenon called overfitting, where the model fits the observed data very well, but does not generalize well on unseen data, can be seen which will be discussed in chapter 3.
