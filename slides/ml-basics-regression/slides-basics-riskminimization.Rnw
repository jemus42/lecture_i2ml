% Introduction to Machine Learning
% Day 1

% Set style/preamble.Rnw as parent.
<<set-parent, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@
% Load all R packages and set up knitr
<<setup-r, child="../../style/setup.Rnw", include = FALSE>>=
@

%! basics-learners

\lecturechapter{Losses \& Risk Minimization}
\lecture{Introduction to Machine Learning}

\begin{vbframe}{Motivation}
  \begin{itemize}
    \item Assume we trained a model to predict flat rent based on some features
    (size, location, age, ...).
    \item The real rent of a new flat, that the model never saw before, is
    EUR 1600, our model predicts EUR 1300.
    \item How do we measure the performance of our model? 
    \item Need to define a suitable criterion, e.g.:
    \begin{itemize}
      \item Absolute error $|1600 - 1300| = 300$
      \item Squared error: $(1600 - 1300)^2 = 90000$\\
      (puts more emphasis on predictions that are far off the mark)
    \end{itemize}
    \item The choice of this metric has a major influence on the final model, because it determines the result of our \textbf{optimization}, i.e., what constitutes a \emph{good} model.
    \item the metric we use is called the \textbf{loss function}. 
    \item The choice of loss function defines the \textbf{risk} part of a learner. 
  \end{itemize}
\end{vbframe}


\begin{vbframe}{Risk Minimization}
\begin{itemize}
    \item The \enquote{goodness} of a prediction $\fx$ is measured by a \textbf{loss function} $\Lxy$ that quantifies how \enquote{close} $\fx$ is to $y$. For example, $\Lxy = |\fx - y|$.
    \item The ability of a model $f$ to reproduce the association between $x$ and $y$ that is
    present in the data $\D$ can be measured by the average loss: the \textbf{empirical risk}
    $$
  \riske(f) = \frac{1}{n} \sumin \Lxyi.
  $$
   \item Learning then amounts to \textbf{empirical risk minimization} -- figuring out which model $f$ has the smallest average loss:
$$
\fh = \argmin_{f \in \Hspace} \riske(f).
$$
\end{itemize}
\framebreak

Since the model $f$ is usually controlled by \textbf{parameters} $\theta$ in a parameter space $\Theta$, this becomes:

\begin{eqnarray*}
\riske(\theta) & = & \frac{1}{n} \sumin \Lxyit \cr
\hat{\theta} & = & \argmin_{\theta \in \Theta} \riske(\theta)
\end{eqnarray*}

Most learners in ML try to solve the above \emph{optimization problem}, which
implies a tight connection between ML and optimization.

\framebreak

\begin{itemize}
\item For regression tasks, the loss often only depends on the residual $\Lxy = L(y - \fx) = L(\eps)$.
\item Since learning can be re-phrased as minimizing the loss, the choice of loss strongly affects the computational difficulty of learning:
\begin{itemize}
    \item smoothness of $\riske(\theta)$ in $\theta$
    \item can gradient-based methods be applied to minimize $\riske(\theta)$?
    \item uni- or multimodality of $\riske(\theta)$ over $\Theta$. \\
\end{itemize}
\item The choice of loss implies which kinds of errors are important or not -- requires \emph{domain knowledge}!
\item For learners that correspond to probabilistic models, the loss determines / is equivalent to distributional assumptions.
\end{itemize}
\end{vbframe}
\endlecture

