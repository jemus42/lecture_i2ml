% Set style/preamble.Rnw as parent.
<<set-parent, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@
% Load all R packages and set up knitr
<<setup-r, child="../../style/setup.Rnw", include = FALSE>>=
@

%! basics-supervised

\lecturechapter{Introduction: Models \& Learners}

\lecture{Introduction to Machine Learning}


\begin{frame}{What is a Model?}

%A model takes the features of new observations and produces a prediction
%\(\hat{y}\) of our target variable \(y\):

A \textbf{model} (or hypothesis) $f : \mathcal{X} \rightarrow \R^g$ is a function that maps feature vectors to predicted scores.\\
(In normal regression, $g=1$, and for classification see later.)\\
A hypothesis space $\Hspace$ is a set of such functions.

% FIGURE SOURCE: https://drive.google.com/open?id=1bc6EQSsHEuVnyqFGX9E8oNfwOjAwVglRaIllxnOjLBo Page 1
\begin{center}\includegraphics[width=0.9\textwidth]{figure_man/the_model_web} \end{center}

\end{frame}

\begin{frame}{What is a Model?}
% FIGURE SOURCE: https://drive.google.com/open?id=1WLPubv9vxLL-JIlHAtsvTBBG5pbF4xgRGW_prkOAEnE Page 3
\begin{center}\includegraphics[width=\textwidth]{figure_man/what_is_a_model_web} \end{center}

In supervised ML, we want to learn the function \(f\) \textbf{automatically from labeled data}, to apply it to new data.

\end{frame}

\begin{frame}{What is a Learner?}

A \textbf{learner} (inducer, algorithm) 
\begin{itemize}
\item takes a data set with features and targets
(\textbf{training set}, $\in \mathcal{X}\, \times \,\mathcal{Y}$)  
\item and produces a \textbf{model}, i.e., a function $f:\, \mathcal{X} \to \R^g$ from a hypothesis space $\Hspace$.\\
\end{itemize}

So: Applying a learning algorithm means coming up with a model based on
training data.\\
%(formally, it maps from $\{((x^{(1)},y^{(1)}),...,(x^{(n)},y^{(n)}))|1 \leq i \leq n < \infty ,x^{(i)} \in \mathcal{X},y^{(i)}, \in \mathcal{Y}\} to \mathcal{H}$).

\vspace{-0.5cm}

\scriptsize

% FIGURE SOURCE: https://drive.google.com/open?id=1bc6EQSsHEuVnyqFGX9E8oNfwOjAwVglRaIllxnOjLBo Page 2
\begin{center}\includegraphics[width=0.7\textwidth]{figure_man/the_inducer_web} \end{center}

\normalsize

\end{frame}

\begin{frame}{How to Evaluate Models}

Compare predictions from model with observed target values:

\scriptsize

% FIGURE SOURCE: https://drive.google.com/open?id=1dTc5act2POjELGuD8wFIUbPxG0QRZlg1PaYdHGU-FJM
\begin{center}\includegraphics[width=0.8\textwidth]{figure_man/eval_inducer1_web} \end{center}
\lz\lz
(... More later.)
\end{frame}

\begin{frame}{Components of a Learner}

Nearly all supervised learning training algorithms can be described
in terms of three components:

\begin{center}
\textbf{Learning = Hypothesis Space + Risk + Optimization}
\end{center}

\begin{itemize}
\item
  \textbf{Hypothesis Space:} Defines (and restricts!) which kind of model \(f\) can be learned from the data.
\item
  \textbf{Risk:} A metric that quantifies how well a specific model performs on a
  given data set. This defines how to compare observed values to predictions and allows us to rank candidate models in order to choose the best one.
\item
  \textbf{Optimization:} Defines how to search for the best model in the \textbf{hypothesis space}, typically guided by the metric used for the \textbf{risk}.
\item
  All of these components represent important choices in ML which can
  have drastic effects:
  \newline
  By making smart choices here, we can tailor learners to specific problems
  - but that usually requires quite a lot of experience and deeper
  insights into ML.
\end{itemize}

\end{frame}

% \begin{frame}{Components of a Learner}
%
% \begin{table}[]
% \begin{tabular}{lllll}
%  \textbf{Representation} & \textbf{Evaluation} &  \textbf{Optimization}&  &  \\
% Instances / Neighbors & Squared error & Gradient descent &  \\
% Linear functions & Likelihood & Stochastic gradient descent  &  \\
% Decision trees & Information gain & Quadratic programming & \\
% Set of rules & K-L divergence & Greedy optimization & \\
% Neural networks & & Combinatorial optimization & \\
% Graphical models & & \\
% \end{tabular}
% \end{table}
%
% Note: What is on the same line above does not belong together!
%
% \end{frame}

\begin{frame}[squeeze]{Components of a Learner}
\vskip -.5em
\begin{footnotesize}

$\textbf{Hypothesis Space} :\begin{cases} 
\text{Step functions} \\
\text{Linear functions}\\
\text{Decision trees}\\
\text{Sets of rules}\\
\text{Neural networks}\\
\text{Graphs}\\
\text{Tesselation}\\
\text{...}
\end{cases}$

$\phantom{Hypothesis Space } \textbf{Risk} :\begin{cases}
\text{Squared error}\\
\text{Misclassification}\\
\text{Likelihood}\\
\text{Information gain}\\
\text{...}
\end{cases}$

$\phantom{hypothesis space risk} \textbf{Optimization} :\begin{cases}
\text{Gradient descent}\\
\text{Quadratic programming}\\
\text{Combinatorial optimization}\\
\text{Genetic algorithms}\\
\text{...}
\end{cases}$

\end{footnotesize}
\end{frame}

\endlecture
