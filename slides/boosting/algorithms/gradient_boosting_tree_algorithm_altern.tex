\begin{algorithm}[H]
  \begin{footnotesize}
  \begin{center}
  \caption{Tree Algorithm for Gradient Boosting.}
    \begin{algorithmic}[1]
      \State \textbf{input: } All observations $\mathcal{N}$ and risk function $\mathcal{R}$
      \State \textbf{output: } $\mathcal{N}_l^{s^*_{opt}}$ and $\mathcal{N}_r^{s^*_{opt}}$
      \For{$j = \xv_1 \dots \xv_p$}
      \For{every split point $s$}
          %\State For all $i$: $\rmi = -\left[\fp{\Lxyi}{\fxi}\right]_{f=\fmdh}$
          %\State Fit regr. tree to the $\rmi$, giving terminal regions $\Rtm,
          %\ t = 1,\ldots,\Tm$
        %\For{$t = 1 \to \Tm$}
       % $$
        %\hat{\mathbf{c}}^{[m]} = \argmin_{(c_1,\dots,c_{T^{[m]}})}\sum_{i = 1}^n L(\yi, \fmdh(\xi) + \bmm(\xi, c_1,\dots,c_{T^{[m]}})).
        %$$
         \State $\mathcal{N}_l^s = \{ i \in \mathcal{N}\}_{j^{(i)} \leq s}$
            \State $\mathcal{N}_r^s = \{i \in \mathcal{N}\}_{j^{(i)} > s}$ 
              
            % objective I for lambda_C and split point t
            \State Find $c$ which minimizes $\mathcal{R}$ for each node
            \State $\mathcal{I}(s) = \mathcal{R}(\mathcal{N}_l^s) + \mathcal{R}(\mathcal{N}_r^s)$
        \EndFor
        % find optimal split point t* for lambda_C
        \State $s^*_{j} \in \argmin\nolimits_s \mathcal{I}(s)$
       
         % \State $\fmh_t = \argmin_{\fmdh(\xi) + c} \sum \limits_{\xi \in \Rtm} L(\yi, \fmdh(\xi) + c)$
        %\EndFor
        %\State $\bmmh(\xv) = \sum_{t=1}^{T} \ctmh \mathds{1}_{\{x \in R_t\}} $
        %\State Update $\fmh(\xv) = \fmdh(\xv) + \bmmh(\xi, c_1,\dots,c_{T^{[m]}})$
      \EndFor
      \State $s^*_{opt} \in \argmin\nolimits_s^*_{j} \mathcal{I}(s^*_{j})$, $j = 1 \dots p$
    \end{algorithmic}
    \end{center}
    \end{footnotesize}
\end{algorithm}
