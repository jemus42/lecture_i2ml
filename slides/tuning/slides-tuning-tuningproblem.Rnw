<<setup-child, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@
% Load all R packages and set up knitr
<<setup, child="../../style/setup.Rnw", include = FALSE>>=
@

%! includes: tuning-intro

\lecturechapter{Hyperparameter Tuning - How does it work \& why is it hard?}
\lecture{Introduction to Machine Learning}
\sloppy

\begin{frame}{Tuning}

\vskip 3em
Recall: \textbf{Hyperparameters} $\lambda$ are parameters that are \emph{inputs} to the 
training problem, in which a learner $\inducer$ mimizes the empirical risk on a training data set in order
to find optimal \textbf{model parameters} $\theta$ which define the fitted model $\fh$.
\vskip 2em

\textbf{(Hyperparameter) Tuning} is the process of finding good model hyperparameters $\lambda$. 
\end{frame}


\begin{vbframe}{Tuning: A bi-level optimization problem} 

\vspace{0.2cm} 

We face a \textbf{bi-level} optimization problem: The well-known risk minimization problem to find $\hat f$ is \textbf{nested} within the outer hyperparameter optimization (also called second-level problem):

\begin{center}
\begin{figure}
% FIGURE SOURCE: https://docs.google.com/presentation/d/14xwcs5zncTjFL4hIHAprjZMmyGIPqk5vs8DS32vEAvQ/edit?usp=sharing
\includegraphics[width=0.8\textwidth]{figure_man/riskmin_bilevel3.png}
\end{figure}
\end{center}

\framebreak 

We formally state the nested hyperparameter tuning problem as: 

$$
\min_{\lambda \in \Lambda} \GEh{\Dtest}\left(\inducer(\Dtrain, \lambda)\right) 
$$

\begin{itemize}
\item The learner $\inducer(\Dtrain, \lambda)$ takes a training dataset as well as hyperparameter settings $\lambda$ (e.g. the maximal depth of a classification tree) as an input. 
\item $\inducer(\Dtrain, \lambda)$ performs empirical risk minimization on the training data and returns the optimal model $\hat f$ for the given hyperparameters. 
\end{itemize}

\framebreak

The components of a tuning problem are: 

\begin{itemize}
\item The dataset
\item The learner (possibly: several competing learners?) that is tuned %(e.g. a decision tree classifier)
\item The learner's hyperparameters and their respective regions-of-interest over which we optimize % (e.g. $\texttt{tree depth} \in \{1, 2, ..., 20\}$)
\item The performance measure, as determined by the application.\\ Not necessarily identical to the loss function that defines the risk minimization problem for the learner!\\ 
We could even be interested in multiple measures simultaneously, e.g., accuracy and computation time of our model, TPR and PPV, etc. 
\item A (resampling) procedure for estimating the predictive performance: The expected performance on unseen data can be estimated by holdout (i.e., a single train-test-split) or more advanced techniques like cross-validation.
More on this later.
\end{itemize}

\framebreak 

\begin{center}
\begin{figure}
% FIGURE SOURCE: https://docs.google.com/presentation/d/1JUtguuVBgidcqD0IdFFIiKH9zqYzM6YRjCqC53V90dA/edit?usp=sharing
\includegraphics[width=1.2\textwidth]{figure_man/autotune_in_model_fit.pdf}
\end{figure}
\end{center}

\end{vbframe}


\begin{vbframe}{Tuning Pipelines}

\begin{itemize}
\item Many other factors like 
\begin{itemize}
\item optimization control settings, 
\item preprocesssing like scaling or centering of features
\item algorithmic variants in the fitting procedure 
\end{itemize}
can influence model performance in non-trivial ways. It is extremely hard to guess 
the correct choices here.
\item Even \textbf{model selection}, i.e., the choice of the learner itself (e.g. logistic regression, decision tree, random forest) can be seen as a hyperparameter tuning problem. 
\item In general, we might be interested in optimizing an entire ML \enquote{pipeline} (including preprocessing, feature engineering, model selection and all other model-relevant operations). 
\end{itemize}


\vskip 6em
\begin{figure}
%source?
\includegraphics[width = 1\textwidth]{figure_man/automl1.png}
\end{figure}


\end{vbframe}


% \framebreak

% Possible scenarios for finding default hyperparameters:

% \begin{itemize}
%   \item If the learner's performance is fairly insensitive to changes of a hyperparameter, we don't really have to worry as long as we remain within the range of reasonable values.
%   \item Constant default: we can benchmark the learner across a broad range of data sets and scenarios and try to find hyperparameter values that work well in many different situations. Quite optimistic?
%   \item Dynamic (heuristic) default: We can benchmark the learner across a broad range of data sets and scenarios and try to find an easily computable function that sets the hyperparameter in a data dependent way,
%   e.g. using \texttt{mtry}$ = p/3$ for RF.\\
%     How to construct or learn that heuristic function, though...?
%   \item In some cases, can try to set hyperparameters optimally by extracting more info from the fitted model. E.g. \texttt{ntrees} for a random forest (does OOB error increase or decrease if you remove trees from the ensemble?).
% \end{itemize}
% \end{vbframe}




% \begin{vbframe}{Hyperparameter Tuning}
% % \begin{itemize}
% % \item Optimize hyperparameters for learner w.r.t. prediction error
% Tuner proposes configuration, eval by resampling, tuner receives performance, iterate
% % \end{itemize}
% \begin{columns}[c, onlytextwidth]
% \column{0.45\textwidth}
% % FIGURE SOURCE: No source
%   \includegraphics[trim={0cm 0cm 0cm 0cm}, clip, width=1.2\textwidth]{figure_man/chain.jpg}
% \column{0.45\textwidth}
%   FIGURE SOURCE: https://drive.google.com/open?id=1wY3aUZxIMZPje3vR0t2yWiDMx_osXRCi
% \includegraphics[trim={1cm 0cm 1cm 0cm}, clip, width=1.2\textwidth]{figure_man/tuning_process.jpg}
% \end{columns}


% \end{vbframe}


\begin{vbframe}{Why is tuning so hard?}
\begin{itemize}
%\item Lots of literature exists for models, far less on efficient tuning.
\item Tuning is derivative-free (\enquote{black box problem}): It is usually impossible to compute derivatives of the objective (i.e., the resampled performance measure) that we optimize with regard to the HPs. All we can do is evaluate the performance for a given hyperparameter configuration.
\item Every evaluation requires one or multiple train and predict steps of the learner. I.e., every evaluation is very \textbf{expensive}.
\item Even worse: the answer we get from that evaluation is \textbf{not exact, but stochastic} in most settings, as we use resampling.
% \item Even worse: the function value we get from that evaluation is \textbf{likely also biased} -- it is difficult to evaluate the tested hyperparameter settings \emph{honestly}, i.e., in such a way that we neither over- nor underestimate their performance if we only have a limited amount of data available. (Remember resampling-based performance evaluation \& its problems -- this gets worse where tuning comes into play.)
\item Categorical and dependent hyperparameters aggravate our difficulties: the space of hyperparameters we optimize over has a non-metric, complicated structure.
\item For large and difficult problems parallelizing the computation seems relevant, to evaluate multiple HP configurations in parallel or to speed up the resampling-based performance evaluation
\end{itemize}
\end{vbframe}

\endlecture

