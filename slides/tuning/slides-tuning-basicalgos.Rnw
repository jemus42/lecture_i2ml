<<setup-child, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@
% Load all R packages and set up knitr
<<setup, child="../../style/setup.Rnw", include = FALSE>>=
@

%! includes: tuning-tuningproblem

\lecturechapter{Hyperparameter Tuning - Techniques}
\lecture{Introduction to Machine Learning}
\sloppy


\begin{vbframe}{Grid search}

\begin{itemize}
\item Simple technique which is still quite popular, tries all
HP combinations on a multi-dimensional discretized grid
\item For each hyperparameter a finite set of candidates is predefined
\item Then, we simply search all possible combinations in arbitrary order
\end{itemize}

\begin{footnotesize}
\begin{center}
Grid search over 10x10 points
\end{center}
\end{footnotesize}

<<fig.height=3.5, fig.align = "center">>=
plotTune = function(d) {
  d$TestAccuracy = mvtnorm::dmvnorm(x = d, mean = c(5,5), sigma = 40 * diag(2)) * 120 + 0.4
  pl = ggplot(data = d, aes(x = x, y = y, color = TestAccuracy))
  pl = pl + geom_point(size = d$TestAccuracy * 4)
  pl = pl + xlab("Hyperparameter 1") + ylab("Hyperparameter 2") + coord_fixed()
  return(pl)
}
x = y = seq(-10, 10, length.out = 10)
d = expand.grid(x = x, y = y)
pl = plotTune(d)
print(pl)
@


\framebreak

\begin{blocki}{Advantages}
\item Very easy to implement
\item All parameter types possible
\item Parallelizing computation is trivial
\end{blocki}

\begin{blocki}{Disadvantages}
\item  Scales badly: Combinatorial explosion
\item  Inefficient: Searches large irrelevant areas
\item  Arbitrary: Which values / discretization?
\end{blocki}
\end{vbframe}


\begin{vbframe}{Random search}

\begin{itemize}
\item Small variation of grid search
\item Uniformly sample from the region-of-interest
\end{itemize}


\begin{footnotesize}
\begin{center}
Random search over 100 points
\end{center}
\end{footnotesize}

<<fig.height=3.5>>=
x = runif(40, -10, 10)
y = runif(40, -10, 10)
d = data.frame(x = x, y = y)
pl = plotTune(d)
print(pl)
@

\framebreak

\begin{blocki}{Advantages}
\item Like grid search: Very easy to implement, all parameter types possible, trivial parallelization
\item Anytime algorithm: Can stop the search whenever our budget for computation is exhausted, or continue until we reach our performance goal.
\item No discretization: each individual parameter is tried with a different value every time
\end{blocki}

\begin{blocki}{Disadvantages}
\item Inefficient: many evaluations in areas with low likelihood for improvement
\item Scales badly: high dimensional hyperparameter spaces need \emph{lots} of samples to cover.
\end{blocki}
\end{vbframe}

\begin{vbframe}{Tuning Example}

Tuning random forest with random search and 5CV on the \texttt{sonar} data set for AUC:

\begin{footnotesize}
\begin{center}
\begin{tabular}{|l|l|l|l}
Parameter          &  Type     & Min & Max \\
\hline
\texttt{num.trees}     & integer  & 3 & 500 \\
\texttt{mtry}          & integer  & 5 & 50  \\
\texttt{min.node.size} & integer  & 10 & 100\\
\end{tabular}
\end{center}
\end{footnotesize}

<<fig.height=3>>=
library(ggplot2)
tr = BBmisc::load2("rsrc/tune_example.RData")
df = as.data.frame(tr$opt.path)
ggd = df[, c("dob", "auc.test.mean")]
colnames(ggd) = c("iter", "auc")
ggd$auc = cummax(ggd$auc)
pl = ggplot(ggd, aes(x = iter, y = auc))
pl = pl + geom_line() 
pl = pl + theme_bw()
pl = pl + 
  theme(axis.text=element_text(size=18), axis.title=element_text(size=22)) +
  ylab("Maximal AUC") + xlab("Iterations")
print(pl)
@

\end{vbframe}

\endlecture
