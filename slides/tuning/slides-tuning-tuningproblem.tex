\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R



\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage{dsfont}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{colortbl}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{bm}
\usetikzlibrary{shapes,arrows,automata,positioning,calc,chains,trees, shadows}
\tikzset{
  %Define standard arrow tip
  >=stealth',
  %Define style for boxes
  punkt/.style={
    rectangle,
    rounded corners,
    draw=black, very thick,
    text width=6.5em,
    minimum height=2em,
    text centered},
  % Define arrow style
  pil/.style={
    ->,
    thick,
    shorten <=2pt,
    shorten >=2pt,}
}
\usepackage{subfig}


% Defines macros and environments
\input{../../style/common.tex}

%\usetheme{lmu-lecture}
\newcommand{\titlefigure}{figure_man/riskmin_bilevel3.png}
\newcommand{\learninggoals}{
\item Understand tuning as a bi-level optimization problem
\item Know the components of a tuning problem
\item Be able to explain what makes tuning a complex problem}
\usepackage{../../style/lmu-lecture}

\let\code=\texttt
\let\proglang=\textsf

\setkeys{Gin}{width=0.9\textwidth}

\title{Introduction to Machine Learning}
% \author{Bernd Bischl, Christoph Molnar, Daniel Schalk, Fabian Scheipl}
\institute{\href{https://compstat-lmu.github.io/lecture_i2ml/}{compstat-lmu.github.io/lecture\_i2ml}}
\date{}

\setbeamertemplate{frametitle}{\expandafter\uppercase\expandafter\insertframetitle}



\begin{document}

% Load all R packages and set up knitr

% This file loads R packages, configures knitr options and sets preamble.Rnw as parent file
% IF YOU MODIFY THIS, PLZ ALSO MODIFY setup.Rmd ACCORDINGLY...








% Defines macros and environments
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/ml-boosting.tex}
\input{../../latex-math/ml-automl.tex}

%! includes: tuning-intro

\lecturechapter{Hyperparameter Tuning - Problem Definition }
\lecture{Introduction to Machine Learning}
\sloppy

\begin{frame}{Tuning}

\vskip 3em
Recall: \textbf{Hyperparameters} $\lambdav$ are parameters that are \emph{inputs} to the 
training problem in which a learner $\inducer$ minimizes the empirical risk on a training data set in order
to find optimal \textbf{model parameters} $\thetab$ which define the fitted model $\fh$.
\vskip 2em

\textbf{(Hyperparameter) Tuning} is the process of finding good model hyperparameters $\lambdav$. 

% \begin{vbframe}{Hyperparameter Tuning}
% \begin{itemize}
% \item Optimize hyperparameters for learner w.r.t. prediction error
% Tuner proposes configuration, eval by resampling, tuner receives performance, iterate
% \end{itemize}
% \begin{columns}[c, onlytextwidth]
% \column{0.45\textwidth}
% FIGURE SOURCE: No source
  % \includegraphics[trim={0cm 0cm 0cm 0cm}, clip, width=1.2\textwidth]{figure_man/chain.jpg}
% \column{0.45\textwidth}
  % FIGURE SOURCE: https://drive.google.com/open?id=1wY3aUZxIMZPje3vR0t2yWiDMx_osXRCi
% \includegraphics[trim={1cm 0cm 1cm 0cm}, clip, width=1.2\textwidth]{figure_man/tuning_process.jpg}
% \end{columns}

% \end{vbframe}

\end{frame}


\begin{vbframe}{Tuning: A bi-level optimization problem} 

\vspace{0.2cm} 

We face a \textbf{bi-level} optimization problem: The well-known risk minimization problem to find $\fh$ is \textbf{nested} within the outer hyperparameter optimization (also called second-level problem):

\begin{center}
\begin{figure}
% FIGURE SOURCE: https://docs.google.com/presentation/d/14xwcs5zncTjFL4hIHAprjZMmyGIPqk5vs8DS32vEAvQ/edit?usp=sharing
\includegraphics[width=0.8\textwidth]{figure_man/riskmin_bilevel3.png}
\end{figure}
\end{center}

\framebreak
  \footnotesize
  \begin{itemize}
    \item For a learning algorithm $\inducer$ (also inducer) with $d$ hyperparameters, the hyperparameter \textbf{configuration space} is:
      $$\bm{\Lambda}=\Lambda_{1} \times \Lambda_{2} \times \ldots \times \Lambda_{d},$$
      where $\Lambda_{i}$ is the domain of the $i$-th hyperparameter.
    \item The domains can be continuous, discrete or categorical.
    \item For practical reasons, the domain of a continuous or integer-valued hyperparameter is typically bounded.
    \item A vector in this configuration space is denoted as $\bm{\lambda} \in \bm{\Lambda}$.
    \item A learning algorithm $\inducer$ takes a (training) dataset $\D \in \allDatasets$ and a hyperparameter configuration $\lambdav \in \bm{\Lambda}$ and returns a trained model (through risk minimization)

    \vspace*{-0.2cm}
  \begin{eqnarray*}
    \inducer: \preimageInducer &\to& \Hspace \\
    (\D, \lambdav) &\mapsto& \inducer(\D, \lambdav) = \hat f_{\D, \lambdav}
  \end{eqnarray*}
    % \item Additionally, some hyperparameters may only need to be specified if another hyperparameter (or combination of hyperparameters) takes on a certain value.
  \end{itemize}

  % \lz 

  % Note that 

  %   In contrast to the first-level (empirical) risk minimization problem, hyperparameter optimization is also referred to as \textbf{second-level} optimization. The first-level problem can be seen as a subroutine called by the second-level problem: Each evaluation of $\lambdav$ requires to solve the first-level optimization problem.  


%   \framebreak 

%   \begin{itemize}
%     \item search for the \textbf{inducer} hyperparameter $\lambdav$
%     \item that minimizes the \textbf{generalization error}
%       $$
%         \min_{\lambdav} \E_{\D_n \sim \Pxy, (\xv, y) \sim \Pxy} \left(V\left(y, \hat f_{\D, \lambdav}(\xv)\right)\right). 
%       $$
%   \end{itemize}

% We compare: In empirical risk minimization, we 
  
%   \begin{itemize}
%     \item search for the \textbf{model} parameter $\thetab$
%     \item that minimizes the \textbf{empirical risk}
%       $$
%         \min_{\thetab} \sum_{(\xi, \yi) \in \Dtrain} L\left(\yi, \fxi\right). 
%       $$
%   \end{itemize}

%   In hyperparameter optimization, we

%   \begin{itemize}
%     \item search for the \textbf{inducer} hyperparameter $\lambdav$
%     \item that minimizes the \textbf{test error}
%       $$
%         \min_{\lambdav \in \Lambda} \sum_{(\xi, \yi) \in \Dtest} V\left(\inducer(\Dtrain, \lambdav)(\xi), \yi\right). 
%       $$
%   \end{itemize}

%   \framebreak 

    % \framebreak
  
  % The hyperparameter optimization problem is difficult in many ways: 
  \end{vbframe}


\begin{vbframe}{Tuning: A bi-level optimization problem} 
We formally state the nested hyperparameter tuning problem as: 

$$
\min_{\lambdav \in \bm{\Lambda}} \GEh{\Dtest}\left(\inducer(\Dtrain, \lambdav)\right) 
$$

\begin{itemize}
\item The learner $\inducer(\Dtrain, \lambdav)$ takes a training data set as well as hyperparameter settings $\lambdav$ (e.g., the maximal depth of a classification tree) as an input. 
\item $\inducer(\Dtrain, \lambdav)$ performs empirical risk minimization on the training data and returns the optimal model $\fh$ for the given hyperparameters. 
\item Note that for the estimation of the generalization error, more sophisticated resampling strategies like cross-validation can be used.
\end{itemize}

\framebreak

The components of a tuning problem are: 

\begin{itemize}
\item The data set
\item The learner (possibly: several competing learners?) that is tuned %(e.g. a decision tree classifier)
\item The learner's hyperparameters and their respective regions-of-interest over which we optimize % (e.g. $\texttt{tree depth} \in \{1, 2, ..., 20\}$)
\item The performance measure, as determined by the application.\\ Not necessarily identical to the loss function that defines the risk minimization problem for the learner!\\ 
% We could even be interested in multiple measures simultaneously, e.g., accuracy and computation time of our model, TPR and PPV, etc. 
\item A (resampling) procedure for estimating the predictive performance
   % The expected performance on unseen data can be estimated by holdout (i.e., a single train-test-split) or more advanced techniques like cross-validation.
% More on this later.
\end{itemize}

% \framebreak 

% \begin{center}
% \begin{figure}
% FIGURE SOURCE: https://docs.google.com/presentation/d/1JUtguuVBgidcqD0IdFFIiKH9zqYzM6YRjCqC53V90dA/edit?usp=sharing
% \includegraphics[width=1.2\textwidth]{figure_man/autotune_in_model_fit.pdf}
% \end{figure}
% \end{center}

\end{vbframe}




% \framebreak

% Possible scenarios for finding default hyperparameters:

% \begin{itemize}
%   \item If the learner's performance is fairly insensitive to changes of a hyperparameter, we don't really have to worry as long as we remain within the range of reasonable values.
%   \item Constant default: we can benchmark the learner across a broad range of data sets and scenarios and try to find hyperparameter values that work well in many different situations. Quite optimistic?
%   \item Dynamic (heuristic) default: We can benchmark the learner across a broad range of data sets and scenarios and try to find an easily computable function that sets the hyperparameter in a data dependent way,
%   e.g. using \texttt{mtry}$ = p/3$ for RF.\\
%     How to construct or learn that heuristic function, though...?
%   \item In some cases, can try to set hyperparameters optimally by extracting more info from the fitted model. E.g. \texttt{ntrees} for a random forest (does OOB error increase or decrease if you remove trees from the ensemble?).
% \end{itemize}
% \end{vbframe}









\begin{vbframe}{Why is tuning so hard?}
  \begin{itemize}
\item Tuning is derivative-free (\enquote{black box problem}): It is usually impossible to compute derivatives of the objective (i.e., the resampled performance measure) that we optimize with regard to the HPs. All we can do is evaluate the performance for a given hyperparameter configuration.
\item Every evaluation requires one or multiple train and predict steps of the learner. I.e., every evaluation is very \textbf{expensive}.
\item Even worse: the answer we get from that evaluation is \textbf{not exact, but stochastic} in most settings, as we use resampling.
\item Categorical and dependent hyperparameters aggravate our difficulties: the space of hyperparameters we optimize over has a non-metric, complicated structure.
  \end{itemize}

  \end{vbframe}

\endlecture

\end{document}
