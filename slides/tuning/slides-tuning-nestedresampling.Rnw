<<set-parent, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@

% Load all R packages and set up knitr
<<setup, child="../../style/setup.Rnw", include = FALSE>>=
@
%! includes: tuning-trainvalidtest, performance-resampling

\lecturechapter{Tuning: Nested Resampling}
\lecture{Introduction to Machine Learning}

\begin{vbframe}{Nested Resampling}
Just like we can generalize holdout splitting to resampling to get more reliable estimates of the predictive performance, we can generalize the training/validation/test approach to \textbf{nested resampling}.
\vskip 2em
This results in two nested resampling loops, i.e., resampling strategies for both tuning and outer evaluation.
% \vskip 2em
% Let's look at this for a simple example: say we want to find out whether a logistic regression model or a $k$-NN classifier performs better on some data set. 

% \framebreak
% FIGURE SOURCE: https://docs.google.com/presentation/d/1W9nPHJa39Tkzzp37ZeRsEaSZjXMdFjH-rmIpimOKZKA/edit#slide=id.g61fd3b961b_0_1260
% \begin{center}\includegraphics[page = 1, width = \textwidth]{figure_man/Outer_CV.pdf}\end{center}

% \begin{center}\includegraphics[page = 2]{figure_man/Outer_CV.pdf}\end{center}

% \begin{center}\includegraphics[page = 3]{figure_man/Outer_CV.pdf}\end{center}

% \begin{center}\includegraphics[page = 4]{figure_man/Outer_CV.pdf}\end{center}

% \framebreak

\framebreak

Assume we want to tune over a set of candidate HP configurations $\lambda_i; i = 1, \dots$ with 4-fold CV in the inner resampling and 3-fold CV in the outer loop. The outer loop is visualized as the light green and dark green parts.

\vspace*{-0.3cm}

% FIGURE SOURCE: No source
\begin{center}\includegraphics[width = 0.7\textwidth]{figure_man/Nested_Resampling.png}\end{center}

\framebreak

\begin{footnotesize}
In each iteration of the outer loop we:
\begin{itemize}
\item Split off the light green testing data
\item Run the tuner on the dark green part of the data, e.g.,
  evaluate each $\lambda_i$ through fourfold CV on the dark green part
\end{itemize}
\end{footnotesize}

% FIGURE SOURCE: No source
\begin{center}\includegraphics[width = 0.7\textwidth]{figure_man/Nested_Resampling.png}\end{center}

\framebreak

\begin{footnotesize}
In each iteration of the outer loop we:
\begin{itemize}
\item Return the winning $\lambda^*$ that performed best on the grey inner test sets
\item Re-train the model on the full outer dark green train set
\item Evaluate it on the outer light green test set
\end{itemize}
\end{footnotesize}

% FIGURE SOURCE: No source
\begin{center}\includegraphics[width = 0.7\textwidth]{figure_man/Nested_Resampling.png}\end{center}

\framebreak

\begin{footnotesize}
The error estimates on the outer samples (light green) are unbiased because this data was strictly excluded from the model-building process of the model that was tested on.
\end{footnotesize}

% FIGURE SOURCE: No source

\begin{center}\includegraphics[width = 0.7\textwidth]{figure_man/Nested_Resampling.png}\end{center}

\end{vbframe}



\begin{vbframe}{Nested Resampling - Instructive Example}

Taking again a look at the motivating example and adding a nested resampling outer loop, we get the expected behavior:

<<fig.height=3.5, echo = FALSE>>=
load("rsrc/overtuning_data.rds")
library(dplyr)
library(ggplot2)

df_overtuning %>%
  group_by(data_dim, tuning_method, number_points) %>%
  dplyr::summarize(performance = mean(performance)) %>%
  mutate(number_points = as.integer(as.character(number_points))) %>%
  ggplot(aes(x = number_points, y = performance, color = data_dim, linetype = tuning_method)) +
    geom_line() +
    xlab("Amount of tried hyperparameter configurations") +
    ylab("Tuned Performance") +
    scale_linetype_discrete(name = "")
@


\end{vbframe}
\endlecture
