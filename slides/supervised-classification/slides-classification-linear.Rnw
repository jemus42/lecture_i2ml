% Set style/preamble.Rnw as parent.
<<set-parent, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@
% Load all R packages and set up knitr
<<setup-r, child="../../style/setup.Rnw", include = FALSE>>=
@

%! includes: classification-basicdefs

\lecturechapter{Classification: Linear Classifiers}
\lecture{Introduction to Machine Learning}
\framebreak


\begin{vbframe}{Linear Classifiers}

Linear classifiers are an important subclass of classification models. 
If the discriminant function(s) $\fkx$ can be specified as linear function(s) (possibly through a rank-preserving,
monotone transformation $g: \R \to \R$), i. e. 

$$
  g(\fkx) = \bm{w}_k^\top \bm{x} + b_k,
$$

we will call the classifier a \textbf{linear classifier}. 
  
  
% Note that this is different from the definition of a linear model in statistics:

\framebreak
  
% VISUALIZE the score
% SHOW THAT THRESHOLD CUT IS LINEAR

  
We can also easily show that the decision boundary between classes $i$ and $j$ is a hyperplane. For every $x$ where there is a tie in scores: 

\begin{eqnarray*}
  \fix &=& \fjx \\
  g(\fix)) &=& g(\fjx) \\
  \bm{w}_i^\top \xv + b_i &=& \bm{w}_j^\top \xv + b_j \\
  \left(\bm{w}_i - \bm{w}_j\right)^\top \xv + \left(b_i - b_j\right) &=& 0 
  % \bm{w}_{ij}^\top \xv + b_{ij} &=& 0 
\end{eqnarray*}

This is a \textbf{hyperplane} separating two classes. 

% \lz

% Note that linear classifiers can represent non-linear decision boundaries in the original input space if we use derived features like higher order interactions, polynomial features, basis function expansions, etc.


\end{vbframe}


\begin{vbframe}{Linear vs Nonlinear Decision Boundary}
\begin{columns}[T]
  \begin{column}{0.5\textwidth}
<<>>=
iris_petal <- makeClassifTask(data = iris[,-(1:2)], target = "Species")
iris_sepal <- makeClassifTask(data = iris[,-(3:4)], target = "Species")
iris_sepal_bin <- makeClassifTask(data = subset(iris[,-(3:4)], Species != "setosa"),
                                  target = "Species")
# plotLearnerPrediction(makeLearner("classif.kknn"), iris_petal, cv=0, prob.alpha = FALSE, gridsize = 100)
# plotLearnerPrediction(makeLearner("classif.kknn"), iris_sepal, cv=0, prob.alpha = FALSE, gridsize = 100)
plotLearnerPrediction(makeLearner("classif.kknn", k = 25),
                      iris_sepal_bin, cv = 0, prob.alpha = FALSE, gridsize = 400) +
  scale_fill_viridis_d()
@
  \end{column}
  \begin{column}{0.5\textwidth}
<<>>=
 plotLearnerPrediction(makeLearner("classif.logreg"),
                      iris_sepal_bin, cv = 0, prob.alpha = FALSE, gridsize = 400) +
  scale_fill_viridis_d()
@
  \end{column}
\end{columns}



\end{vbframe}

\endlecture

