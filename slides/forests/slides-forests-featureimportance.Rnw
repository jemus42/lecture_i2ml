% Introduction to Machine Learning
% Day 4

% Set style/preamble.Rnw as parent.
<<set-parent, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
library(methods)
library(rpart)
library(rpart.plot)
library(randomForest)
library(rattle)
library(smoof)
@

% Load all R packages and set up knitr
<<setup, child="../../style/setup.Rnw", include = FALSE>>=
@

%! includes: forests-intro


\lecturechapter{Random Forests: Feature Importance}
\lecture{Introduction to Machine Learning}

\sloppy


\begin{vbframe}{Variable Importance}

\begin{itemize}
  \item Single trees are highly interpretable
  \item Random Forests as ensembles of trees lose this feature
  \item Contributions of the different features to the model are difficult to evaluate
  \item Way out: variable importance measures
  \item Basic idea: by how much would performance of the random forest decrease if a specific feature were removed or rendered useless?
\end{itemize}


\framebreak

\begin{algorithm}[H]
  \small
  \caption*{Measure based on improvement in split criterion}
  \begin{algorithmic}[0]
    \For{features $x_j$, $j = 1$ to $p$}
    \For{tree base learners $\blmh$, $m = 1$ to $M$}
    \State {Find all nodes $\Np$ in $\blmh$ that use $x_j$.} 
    \State {Compute improvement in splitting criterion achieved by them.}
    \State {Add up these improvements.}
    \EndFor
    \State {Add up improvements over all trees to get feature importance of $x_j$.}
    %\State {This is the feature importance for $x_j$.}
    \EndFor
  \end{algorithmic}
\end{algorithm}
\vskip -2em
\begin{figure}
<<size="footnotesize", fig.height=2.6>>=
model = randomForest(Species ~ ., data = iris, importance = TRUE)
randomForest::varImpPlot(model, main = "")
@
% \caption{Two importance measures on the iris dataset.}
\end{figure}

\framebreak

\begin{algorithm}[H]
  \small
  \caption*{Measure based on permutations of OOB observations}
  \begin{algorithmic}[0]
    \State While growing tree, pass down OOB observations and record predictive accuracy.
    \State Permute OOB observations of $j$-th feature. This destroys the association between the target and the permuted $j$-th feature.
    \State Pass down the permuted OOB observations and evaluate predictive accuracy again.
    \State The decrease of performance induced by permutation is averaged over all trees and
  is used as a measure for the importance of the $j$-th variable.
  \end{algorithmic}
\end{algorithm}

% \framebreak

% <<>>=
% lrn = makeLearner("classif.randomForest", importance = TRUE)
% mod = train(lrn, iris.task)
% mlr::getFeatureImportance(mod)
% @

% \framebreak

% <<echo=TRUE, size="footnotesize", fig.height=4>>=
% rf = getLearnerModel(mod)
% randomForest::varImpPlot(rf,
%   main = "Variable Importance")
% @

% \framebreak

% <<echo=TRUE, size="footnotesize", fig.height=4>>=
% v = generateFilterValuesData(iris.task,
%   method = c("rf.importance", "cforest.importance"))
% plotFilterValues(v)
% @


\end{vbframe}

\begin{vbframe}{Variable Importance based on permutations of OOB observations}
\begin{center}
% FIGURE SOURCE: https://docs.google.com/presentation/d/16gg9PqtEV_Ii_ZBw0zA9GdUIled-6OVkoqArX1ouTmo/edit#slide=id.p
\includegraphics[width = 10.3cm]{figure_man/rF_varImp_permutation_new.pdf}
\end{center}
\end{vbframe}

\endlecture
