\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}

\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi 
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R



\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage{dsfont}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{colortbl}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{bm}
\usetikzlibrary{shapes,arrows,automata,positioning,calc,chains,trees, shadows}
\tikzset{
  %Define standard arrow tip
  >=stealth',
  %Define style for boxes
  punkt/.style={
    rectangle,
    rounded corners,
    draw=black, very thick,
    text width=6.5em,
    minimum height=2em,
    text centered},
  % Define arrow style
  pil/.style={
    ->,
    thick,
    shorten <=2pt,
    shorten >=2pt,}
}
\usepackage{subfig}


% Defines macros and environments
\input{../../style/common.tex}

%\usetheme{lmu-lecture}
\newcommand{\titlefigure}{figure/err_surf}
\newcommand{\learninggoals}{
\item Understand how the risk function is optimized to
  learn the optimal parameters of a model
\item Understand the idea of gradient descent as a basic risk optimizer}

\usepackage{../../style/lmu-lecture}

\let\code=\texttt
\let\proglang=\textsf

\setkeys{Gin}{width=0.9\textwidth}



\title{Introduction to Machine Learning}

\date{}

\setbeamertemplate{frametitle}{\expandafter\uppercase\expandafter\insertframetitle }



\begin{document}
% Introduction to Machine Learning
% Day 1

% Set style/preamble.Rnw as parent.

% Load all R packages and set up knitr

% This file loads R packages, configures knitr options and sets preamble.Rnw as parent file
% IF YOU MODIFY THIS, PLZ ALSO MODIFY setup.Rmd ACCORDINGLY...





% Defines macros and environments
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}

%! includes: basics-learners

\lecturechapter{ML-Basics: Optimization}
\lecture{Introduction to Machine Learning}


\begin{vbframe}{Introduction}
\begin{itemize}
\item We have seen, we can 1-on-1 identify models $f$ with their parametrization $\thetab \in \Theta$. 
\item Hence we can express the associated empirical risk of the model as a function of these parameters: $\risket$.
\item Therefore, when we try to find the best model, we actually traverse on the error surface from a starting point (yellow) with the goal of finding the point with the lowest empirical risk (red).
\end{itemize}
\begin{center}
\begin{figure}[!b]
\includegraphics[trim=2.4cm 2.4cm 2.4cm 2.4cm, width=0.3\textwidth]{figure/err_surf}
\end{figure}
\end{center}

\end{vbframe}
\begin{vbframe}{Introduction}

Formally, this means that we find the best model $\hat f$ parametrized by parameters $\thetabh \in \Theta$ regarding an empirical risk $\riske$ by \textbf{minimizing} $\risket$ with respect to $\thetab$, i.e., 

\[
\thetabh  = \argmin_{\thetab \in \Theta} \risket .
\]

For such a \textbf{(global) minimum} $\thetabh$ it obviously holds that 
\[
\forall \thetab \in \Theta :\quad \riske(\thetabh) \leq \risket .
\]

However, this does not imply that $\thetabh$ is unique by any means. \\
\lz
Which kind of technique we can use to solve the minimization problem strongly depends on the feature space. In this chapter we will focus on purely numeric features.

\end{vbframe}
\begin{vbframe}{Continuous $\riske$}

If the empirical risk $\riske$ is continuous in $\thetab$ we can define a \textbf{local minimum} $\thetabh$, such that
\[
\exists \epsilon > 0\; \forall \thetab \in \left\{\bar\thetab \in \Theta ~\big|~ \left\Vert\thetabh - \bar\thetab\right\Vert < \epsilon\right\}: \quad \riske(\thetabh) \leq \risket .
\]
Clearly every global minimum is also a local minimum (if it exists). \\
In general finding a local minimum is easier than finding a global minimum.

\begin{center}
\begin{figure}[!b]
\includegraphics[width=0.7\textwidth]{figure/g_l_min}
\end{figure}
\end{center}

\end{vbframe}
\begin{vbframe}{Continuously differentiable $\riske$}
\footnotesize
If the empirical risk $\riske$ is continuously differentiable in $\thetab$ then a \textbf{sufficient condition} for $\thetabh$ to be a local minimum is that the gradient 
\[
\frac{\partial}{\partial\thetab}\riske(\thetabh) = 0
\]
and the Hessian $\frac{\partial^2}{\partial\thetab^2}\riske(\thetabh)$ is positive definite. Which makes sense, since, while the gradient can be thought of as the local direction and rate of fastest increase, the Hessian measures the local curvature of $\riske$.

\begin{figure}[!htb]
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth]{figure/grad}
  \caption*{\footnotesize$\frac{\partial}{\partial\thetab}\riske(\thetabh)$}
\endminipage\hfill
\minipage{0.32\textwidth}
  \includegraphics[trim=2.2cm 2.2cm 2.2cm 2.2cm, width=\linewidth]{figure/hess1}
  \caption*{\footnotesize const. pos. def. Hessian}
\endminipage\hfill
\minipage{0.32\textwidth}%
  \includegraphics[trim=2.2cm 2.2cm 2.2cm 2.2cm, width=\linewidth]{figure/hess2}
  \caption*{\footnotesize const. neg. def. Hessian}
\endminipage
\end{figure}

\end{vbframe}
\begin{vbframe}{Least Squares Estimator}
Now, for given features $\Xmat \in \mathbb{R}^{n\times p}$ and target $\yv \in \mathbb{R}^n$, we want to find the best linear model regarding the squared error loss, i.e.,
\[\risket = \left\Vert \Xmat\thetab - \yv\right\Vert_2^2 = \sumin (\thetab^\top\xv^{(i)} - \yi)\;.\]

With the sufficient condition for continously differentiable functions it can be shown that the \textbf{least squares estimator}
\[\thetabh = (\Xmat^\top\Xmat)^{-1}\Xmat^\top\yv.\]
is a local minimum of $\riske$. Since, here, $\riske$ is a convex function it follows that there is only one minimum. Hence $\thetabh$ is the global minimum. \\

\lz \textbf{Note:} Often such an analytical solution to our respective minimization problem does not exist. Therefore we need numerical methods which enable us to find an approximate solution.

\end{vbframe}
\begin{vbframe}{Gradient Descent}
    The simple idea of \textbf{gradient descent} (GD) is to follow iteratively from the $t$-th solution candidate $\thetab^{[t]}$ in the direction of the negative gradient, i.e., the direction of the steepest descent, with a learning rate $\lambda$ to the [$t+1$]-th solution candidate $\thetab^{[t+1]}$, s.t.
\[
    \thetab^{[i+1]} = \thetab^{[i]} - \lambda \frac{\partial}{\partial\thetab}{\riske(\thetab^{[i]})}.
\]

\begin{figure}[!htb]
\minipage{0.32\textwidth}
  \includegraphics[trim=2cm 2cm 2cm 2cm, width=\linewidth]{figure/grad_desc1}  
\endminipage\hfill
\minipage{0.32\textwidth}
  \includegraphics[trim=2cm 2cm 2cm 2cm, width=\linewidth]{figure/grad_desc2}
\endminipage\hfill
\minipage{0.32\textwidth}%
  \includegraphics[trim=2cm 2cm 2cm 2cm, width=\linewidth]{figure/grad_desc3}
\endminipage
\end{figure}

\end{vbframe}
\begin{vbframe}{Further topics}
\begin{itemize}
\item There exist many improvements of the GD method, e.g., we could also optimize the learning rate $\lambda$.
\item GD is a so-called first-order method. Second-order methods use the Hessian (which must therefore exist) to refine the search direction.
% \item If some parameters are dependent of each other, we can model such dependicies either by \textbf{equality} or \textbf{inequality constraints}, i.e., 
% \[g(\thetab) = 0 \quad \text{or} \quad h(\thetab) \geq 0.\]
% There exist numerical methods to solve constrained optimization problems, such as sequential quadratic programming.
\item If the gradient of GD is not derived from the empirical risk of the whole data set, but instead from a randomly selected subset of it, we call the respective method \textbf{stochastic gradient descent} (SGD). For high-dimensional problems this can lead to a higher computational efficiency.
\item Often it is desirable to not allow arbitrarily large $\Vert \thetabh \Vert$, since this could result, among other things, in numerical instability of the method. This procedure is called \textbf{regularization}.
\end{itemize}
\end{vbframe}


\begin{vbframe}{Further topics}
    learning vs optimuzation,.,.,.
\end{vbframe}


\endlecture

\end{document}
