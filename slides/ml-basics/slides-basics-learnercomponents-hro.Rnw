% Set style/preamble.Rnw as parent.
<<set-parent, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@
% Load all R packages and set up knitr
<<setup-r, child="../../style/setup.Rnw", include = FALSE>>=
@

%! basics-riskminimization, basics-learners

\lecturechapter{Introduction: Components of a Learner}
\lecture{Introduction to Machine Learning}

\begin{frame}{Components of a Learner}

Nearly all supervised learning algorithms can be described
in terms of three components:

\begin{center}
\textbf{Learning = Hypothesis Space + Risk + Optimization}
\end{center}

\begin{itemize}
\item
  \textbf{Hypothesis Space:} Defines (and restricts!) what kind of model \(f\) can be learned from the data.
\item
  \textbf{Risk:} A metric that quantifies how well a specific model performs on a
  given data set. This defines how to compare observed values to predictions and allows us to rank candidate models in order to choose the best one.
\item
  \textbf{Optimization:} Defines how to search for the best model in the \textbf{hypothesis space}, typically guided by the metric used for the \textbf{risk}.
\end{itemize}

\end{frame}

\begin{frame}{Learning = Hypothesis Space + Risk + Optimization}
By decomposing learners into these components
\begin{itemize}
\item we have a framework to understand how they work 
\item we can more easily evaluate for what problems they may be more or less suitable
\item we can tailor learners to specific problems 
\end{itemize}
\end{frame}

\begin{frame}{Supervised Learning, Formalized:}

A \textbf{learner} 
\begin{itemize}
\item receives a \textbf{training set} $\D \in \Xspace \times \Yspace$
\item and uses an \textbf{optimization} procedure to find
$$
\fh = \argmin_{f \in \Hspace} \riske(f).
$$
\item for a given \textbf{hypothesis class} $\Hspace$ of \textbf{models} $f:\Xspace \rightarrow \Yspace$
\item based on a \textbf{risk} function $\riske(f)$ that quantifies the performance of $f \in \Hspace$ on $\D$
\end{itemize}
\lz\lz\lz
{\footnotesize (This does not cover all special cases, but it's a useful framework for most supervised ML problems.)}
\end{frame}


\begin{frame}[squeeze]{Components of a Learner}
\vskip -.5em
\begin{footnotesize}

$\textbf{Hypothesis Space} :\begin{cases} 
\text{Step functions} \\
\text{Linear functions}\\
\text{Sets of rules}\\
\text{Neural networks}\\
\text{Voronoi tesselations}\\
\text{...}
\end{cases}$

$\phantom{Hypothesis Space RISK RISK} \textbf{Risk} :\begin{cases}
\text{Mean squared error}\\
\text{Misclassification rate}\\
\text{Negative log-likelihood}\\
\text{Information gain}\\
\text{...}
\end{cases}$

$\phantom{hypothesis space risk RISK RISK} \textbf{Optimization} :\begin{cases}
\text{Analytic solution}\\
\text{Gradient descent}\\
\text{Combinatorial optimization}\\
\text{Genetic algorithms}\\
\text{...}
\end{cases}$

\end{footnotesize}
\end{frame}
\endlecture
