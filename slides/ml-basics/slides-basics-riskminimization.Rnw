% Introduction to Machine Learning
% Day 1

% Set style/preamble.Rnw as parent.
<<set-parent, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@
% Load all R packages and set up knitr
<<setup-r, child="../../style/setup.Rnw", include = FALSE>>=
@

%! includes: basics-learners

\lecturechapter{Introduction: Losses \& Risk Minimization}
\lecture{Introduction to Machine Learning}

\begin{frame}{How to Evaluate Models}

Compare predictions from a model with observed target values:

\scriptsize

% FIGURE SOURCE: https://drive.google.com/open?id=1dTc5act2POjELGuD8wFIUbPxG0QRZlg1PaYdHGU-FJM
\begin{center}\includegraphics[width=0.8\textwidth]{figure_man/eval_inducer1_web} \end{center}
\lz\lz
\end{frame}


\begin{vbframe}{Motivation}
  \begin{itemize}
    \item Assume we trained a model to predict flat rent based on some features
    (size, location, age, ...).
    \item The real rent of a flat is EUR 1600, our model predicts EUR 1300.
    \item How do we measure the performance of our model? 
    \item Need to define a suitable criterion, e.g.:
    \begin{itemize}
      \item Absolute error $|1600 - 1300| = 300$
      \item Squared error: $(1600 - 1300)^2 = 90000$\\
      (puts more emphasis on predictions that are far off the mark)
    \end{itemize}
    \item The choice of this metric has a major influence on the final model, because it determines what constitutes a \emph{good} model: it will determine the ranking of the different models $f \in \Hspace$.
    \item the metric we use is called the \textbf{loss function}. 
  \end{itemize}
\end{vbframe}


\begin{vbframe}{Risk Minimization}
\begin{itemize}
    \item The \enquote{quality} of a prediction $\fx$ is measured by a \textbf{loss function} $\Lxy$ that quantifies how \enquote{close} $\fx$ is to $y$. \\
    For example, $\Lxy = |\fx - y|$.
    \item The ability of a model $f$ to reproduce the association between $x$ and $y$ that is
    present in the data $\D$ can be measured by the average loss: the \textbf{empirical risk}
    $$
  \riske(f) = \frac{1}{n} \sumin \Lxyi.
  $$
   \item Learning -- finding the \enquote{best} model -- then amounts to \textbf{empirical risk minimization}:\\    figuring out which model $f$ has the smallest average loss:
$$
\fh = \argmin_{f \in \Hspace} \riske(f).
$$
\end{itemize}
\framebreak

Since the model $f$ is usually defined by \textbf{parameters} $\theta$ in a parameter space $\Theta$, this becomes:

\begin{eqnarray*}
\riske(\theta) & = & \frac{1}{n} \sumin \Lxyit \cr
\hat{\theta} & = & \argmin_{\theta \in \Theta} \riske(\theta)
\end{eqnarray*}

Most learners in ML try to solve the above \emph{optimization problem}, which
implies a tight connection between ML and optimization.

\framebreak

\begin{itemize}
\item For regression tasks, the loss often only depends on the residual $\Lxy = L(y - \fx) = L(\eps)$.
\item The choice of loss implies which kinds of errors are important or not -- requires \emph{domain knowledge}!
\item For learners that correspond to probabilistic models, the loss determines / is equivalent to distributional assumptions.
\item Since learning can be re-phrased as minimizing the loss, the choice of loss strongly affects the computational difficulty of learning:
\begin{itemize}
    \item How smooth is $\riske(\theta)$ in $\theta$?
    \item Is $\riske(\theta)$ differentiable so that we can use gradient-based methods?
    \item Does $\riske(\theta)$ have multiple local minima or saddlepoints over $\Theta$?\\
\end{itemize}

\end{itemize}
\end{vbframe}



\endlecture

