<<set-parent, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@
<<setup, child="../../style/setup.Rnw", include = FALSE>>=
requireNamespace("ROCR")
@
\lecturechapter{Evaluation: ROC Analysis 2}
\lecture{Introduction to Machine Learning}

% \begin{vbframe}{ROC Space}
% \end{itemize}
% \begin{center}
% \includegraphics[width=0.7\textwidth, height=5.0cm]{figure_man/roc-space1.png}
% \end{center}
% \end{vbframe}


\begin{vbframe}{ROC Space}
\begin{itemize}
\item We characterize a classifier by its TPR and FPR values and plot them in a coordinate
      system
\item We could also use 2 different ROC metrics which define a trade-off, like TPR and PPV!
\end{itemize}
<<echo=FALSE, out.height="5cm", fig.align="center">>=
plot_roc_space = function(fpr, tpr, label) {
  d = data.frame(FPR = fpr, TPR = tpr, label = label)
  pl = ggplot(d, aes(x = FPR, y = TPR, label = label))
  pl = pl + geom_point(size = 3)
  pl = pl + geom_text_repel()
  pl = pl + xlim(c(0, 1)) + ylim(c(0,1))
  pl = pl + geom_abline(slope = 1, lty = "dotted")
}

fpr = c(0.1, 0.30, 0.4)
tpr = c(0.7, 0.85, 0.6)
label = c("C1", "C2", "C3")
pl = plot_roc_space(fpr, tpr, label)
pl = pl + geom_segment(x = fpr[1], y = tpr[1], xend = fpr[2], yend = tpr[2], lty = "dotted")
pl = pl + geom_text_repel(data = data.frame(FPR = 0.20, TPR = 0.78, label = "unclear winner"))
pl = pl + geom_segment(x = fpr[1], y = tpr[1], xend = fpr[3], yend = tpr[3], lty = "dotted")
pl = pl + geom_text_repel(data = data.frame(FPR = 0.25, TPR = 0.65, label = "dominates"))
print(pl)
@
\end{vbframe}


\begin{vbframe}{ROC Space}
  \begin{itemize}
  \item The best classifier lies on the top-left corner
  \item The diagonal is worst, where classifiers produce random labels (with different proportions). If each positive $x$ will be randomly classified with 25\% as "pos", $TPR = 0.25$. If we assign each negative $x$ randomly to "pos", $FPR = 0.25$.
\end{itemize}
<<echo=FALSE, out.height="5cm", fig.align="center">>=
fpr = c(0, 1, 0, 0.25, 0.75)
tpr = c(1, 1, 0, 0.25, 0.75)
label = c("Best", "Pos-100%", "Pos-0%", "Pos-25%", "Pos-75%")
pl = plot_roc_space(fpr, tpr, label)
print(pl)
@
\end{vbframe}

\begin{vbframe}{ROC Space}

In practice, we should never obtain a classifier below the diagonal, as inverting the predicted labels -- $0 \rightarrow 1$ and $1 \rightarrow 0$ -- will result in a reflection at the diagonal. Because this inverting results in $TPR2 = 1-TPR1$ and $FPR2 = 1-FPR1$

<<echo=FALSE, out.width="5cm", out.height="5cm", fig.align="center">>=
fpr = c(0.75, 0.25)
tpr = c(0.25, 0.75)
label = c("C1", "C2")
pl = plot_roc_space(fpr, tpr, label)
pl = pl + geom_segment(x = fpr[1], y = tpr[1], xend = fpr[2], yend = tpr[2], lty = "dotted")
print(pl)
@
\end{vbframe}

\begin{vbframe}{ROC and Label Distribution}
ROC curves are insensitive to class distributions
ROC curves are insensitive to the class distribution in the sense that
they are not affected by changes in the ratio $n_+/n_-$ (at prediction).
\begin{table}[]
\centering
\tiny
\begin{tabular}{|l|c|c|}
                \hline
               & Actual Positive & Actual Negative \\ \hline
Pred. Positive & 40            & 25            \\ \hline
Pred. Negative & 10            & 25           \\ \hline
\end{tabular}
\end{table}

Here we have we have a proportion $n_+/n_- = 1$. MCE = 35/100.
Now we double the size of the positive class and change the proportion to $n_+/n_- = 2$. MCE = 45/150 = 30/100.

\begin{table}[]
\centering
\tiny
\begin{tabular}{|l|c|c|}
                \hline
               & Actual Positive & Actual Negative \\ \hline
Pred. Positive & 80            & 25            \\ \hline
Pred. Negative & 20            & 25           \\ \hline
\end{tabular}
\end{table}

$TPR = 0.8$ and $FPR = 0.5$ do not change.

\lz

NB: If we mess around with class proportions during training, the above is not true, as estimated posterior probabilities can
drastically change!

\end{vbframe}



\begin{vbframe}{Scoring Classifiers}
\begin{itemize}
\item A scoring classifier is a model which outputs scores or probabilities, instead of discrete labels, and nearly all modern classifiers can do that.
\item Thresholding flexibly converts measured probabilities to labels.
  Predict $1$ (positive class) if $\fxh > \tau$ else predict $0$.
\item Normally we could use $\tau = 0.5$ to convert, but for imbalanced or cost-sensitive situations another threshold could be much better.
\item After thresholding, any metric defined on labels can be used.
\end{itemize}
\begin{centering}
% FIGURE SOURCE: https://docs.google.com/presentation/d/1GmlgtjSCTHgSAveVGf-x1ojAjGP2llPhFKjn_6M4Sig/edit?usp=sharing
\includegraphics[height=3.5cm,page=2]{figure_man/confusion_matrix_measures}
\end{centering}
\end{vbframe}

\begin{vbframe}{ROC Curve}

\begin{itemize}
  \item Are based on thresholding classifiers
  \item We iterate through all possible threshold, and draw a point in the ROC space (FPR, TPR) for the resulting classifier
  \item The resulting plot is called an ROC curve
  \item Small thresholds will very liberally predict class 1, and result in a potentially higher FPR, but also higher TPR
  \item High thresholds will very conservatively predict class 1, and result in a lower FPR and TPR
  \item As we have not defined the trade-off between false postives and false negative costs,
    we cannot easily select the "best" threshold; but a visual inspection of all possible results seems useful
\end{itemize}
\end{vbframe}

% \begin{vbframe}{ROC Curve}
% \begin{center}
% \includegraphics[width=\textwidth]{figure_man/roc-curves2.png}
% \end{center}
% \end{vbframe}

\begin{vbframe}{ROC Curve}
\begin{itemize}
  \item Rank test observations on decreasing score
  \item Set $\alpha=1$, so we start in $(0, 0)$; we predict everything as "neg"
  \item For each observation $x$ (in the decreasing order).
  \begin{itemize}
    \item Reduce threshold, so prediction for next observation changes
    \item If $x$ is "pos", move TPR $1/n_+$ up, as we have one TP more
    \item If $x$ is "neg", move FPR $1/n_-$ right, as we have one FP more
  \end{itemize}
\end{itemize}
\end{vbframe}


\begin{vbframe}{ROC Curve}

<<echo=FALSE, out.width="0.8\\textwidth", fig.width=6, fig.height=4, fig.align="center">>=
source("rsrc/plot_roc.R")

df_auc = data.frame(
  '#' = 1:12,
  Truth = c("Pos", "Neg")[c(1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2)],
  Score = c(0.95, 0.86, 0.69, 0.65, 0.59, 0.52, 0.51, 0.39, 0.28, 0.18, 0.15, 0.06)
)
names(df_auc) = c("#", "Truth", "Score")

thresh = 0.9
tpr = mlr::measureTPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos")
fpr = mlr::measureFPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos", negative = "Neg")

plotROC(df_auc, thresh)
@

Set threshold $\tau =$ \Sexpr{thresh} yields TPR \Sexpr{tpr} and FPR \Sexpr{fpr}.


\framebreak

<<echo=FALSE, out.width="0.8\\textwidth", fig.width=6, fig.height=4, fig.align="center">>=
thresh = 0.85
tpr = mlr::measureTPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos")
fpr = mlr::measureFPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos", negative = "Neg")

plotROC(df_auc, thresh)
@

Set threshold $\tau =$ \Sexpr{thresh} yields TPR \Sexpr{tpr} and FPR \Sexpr{fpr}.

\framebreak

<<echo=FALSE, out.width="0.8\\textwidth", fig.width=6, fig.height=4, fig.align="center">>=
thresh = 0.66
tpr = mlr::measureTPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos")
fpr = mlr::measureFPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos", negative = "Neg")

plotROC(df_auc, thresh)
@

Set threshold $\tau =$ \Sexpr{thresh} yields TPR \Sexpr{tpr} and FPR \Sexpr{fpr}.

\framebreak

<<echo=FALSE, out.width="0.8\\textwidth", fig.width=6, fig.height=4, fig.align="center">>=
thresh = 0.6
tpr = mlr::measureTPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos")
fpr = mlr::measureFPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos", negative = "Neg")

plotROC(df_auc, thresh)
@

Set threshold $\tau =$ \Sexpr{thresh} yields TPR \Sexpr{tpr} and FPR \Sexpr{fpr}.


\framebreak

<<echo=FALSE, out.width="0.8\\textwidth", fig.width=6, fig.height=4, fig.align="center">>=
thresh = 0.55
tpr = mlr::measureTPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos")
fpr = mlr::measureFPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos", negative = "Neg")

plotROC(df_auc, thresh)
@

Set threshold $\tau =$ \Sexpr{thresh} yields TPR \Sexpr{tpr} and FPR \Sexpr{fpr}.

\framebreak

<<echo=FALSE, out.width="0.8\\textwidth", fig.width=6, fig.height=4, fig.align="center">>=
thresh = 0.3
tpr = mlr::measureTPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos")
fpr = mlr::measureFPR(truth = df_auc$Truth, response = ifelse(df_auc$Score > thresh, "Pos", "Neg"), positive = "Pos", negative = "Neg")

plotROC(df_auc, thresh)
@

Set threshold $\tau =$ \Sexpr{thresh} yields TPR \Sexpr{tpr} and FPR \Sexpr{fpr}.

\framebreak

<<echo=FALSE, out.width="0.8\\textwidth", fig.width=6, fig.height=4, fig.align="center">>=
plotROC(df_auc, 0, highlight = FALSE)
@

\end{vbframe}

\begin{vbframe}{ROC Curve}
\begin{itemize}
  \item The closer the curve to the top-left corner, the better
  \item Unfortunately, ROC curves can also cross
  \item Then, depending on costs and what you want, a different model can be better in different parts of the ROC space
\end{itemize}
<<echo=FALSE, out.height="5cm", fig.align="center">>=
plot_roc_curves = function(d) {
  pl = ggplot(d, aes(x = FPR, y = TPR, col = label))
  pl = pl + geom_line(size = 2)
  pl = pl + xlim(c(0, 1)) + ylim(c(0,1))
  pl = pl + geom_abline(slope = 1, lty = "dotted")
}
n = 10
fpr = seq(0, 1, length.out = n)
tpr1 = pbeta(fpr, shape1 = 0.3, shape2 = 9)
tpr2 = pbeta(fpr, shape1 = 1, shape2 = 3)
tpr3 = pbeta(fpr, shape1 = 2, shape2 = 5)
tpr4 = pbeta(fpr, shape1 = 0.9, shape2 = 1)
d = rbind(
  data.frame(FPR = fpr, TPR = tpr1, label = "very good"),
  data.frame(FPR = fpr, TPR = tpr2, label = "ok1"),
  data.frame(FPR = fpr, TPR = tpr3, label = "ok2"),
  data.frame(FPR = fpr, TPR = tpr4, label = "bad")
)
pl = plot_roc_curves(d)
print(pl)
@
\end{vbframe}


\begin{vbframe}{AUC: Area Under ROC Curve}

\begin{itemize}
  \item The AUC (in [0,1]) is a single metric to evaluate scoring classifiers
  \item AUC = 1: Perfect classifier
  \item AUC = 0.5: Randomly ordered
  \item AUC = 0: Perfect, with inverted labels
\end{itemize}
<<echo=FALSE, fig.height=4, fig.align="center">>=
plotROC(df_auc, 0, table = FALSE, auc = TRUE, highlight = FALSE)
@
\end{vbframe}

\begin{vbframe}{AUC: Area Under ROC Curve}
Interpretation: Probability that classifier ranks a random positive higher than a random negative observation

\begin{center}
% FIGURE SOURCE: https://docs.google.com/presentation/d/1xj9_84181bqFpr0EMqdGHE6dUf_vAf1qcs9z-siUsCw/edit?usp=sharing
\includegraphics[width=0.8\textwidth,page=1]{figure_man/auc_interpretation.pdf}
\end{center}

\end{vbframe}

\begin{vbframe}{Partial AUC}
\begin{itemize}
  \item Sometimes it can be useful to look at a \href{http://journals.sagepub.com/doi/pdf/10.1177/0272989X8900900307}{specific region under the ROC curve}  $\Rightarrow$ partial AUC (pAUC).
  \item Let $0 \leq c_1 < c_2 \leq 1$ define a region.
  \item For example, one could focus on a region with low FPR ($c_1 = 0, c_2 = 0.2$) or a region with high TPR ($c_1 = 0.8, c_2 = 1$):
\end{itemize}

<<partial-roc, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 14, fig.height = 7, out.width="0.7\\textwidth">>=
#library(pROC)
D.ex <- rbinom(200, size = 1, prob = .5)
M1 <- rnorm(200, mean = D.ex, sd = .65)
M2 <- rnorm(200, mean = D.ex, sd = 1.5)

test <- data.frame(D = D.ex, D.str = c("Healthy", "Ill")[D.ex + 1],
                   M1 = M1, M2 = M2, stringsAsFactors = FALSE)

rocobj <- pROC::roc(test$D, test$M1)
par(mfrow = c(1, 2))
pROC::plot.roc(rocobj, print.auc=TRUE, auc.polygon=TRUE, partial.auc=c(1, 0.8), partial.auc.focus="sp", reuse.auc=FALSE, legacy.axes = TRUE, xlab = "fpr", ylab = "tpr", xlim = c(1, 0), ylim = c(0, 1),  auc.polygon.col="red", auc.polygon.density = 20, auc.polygon.angle = 135, partial.auc.correct = FALSE,  print.auc.cex = 2)
pROC::plot.roc(rocobj, print.auc=TRUE, auc.polygon=TRUE, partial.auc=c(1, 0.8), partial.auc.focus="se", reuse.auc=FALSE, legacy.axes = TRUE, xlab = "fpr", ylab = "tpr", xlim = c(1, 0), ylim = c(0, 1),  auc.polygon.col="red", auc.polygon.density = 20, auc.polygon.angle = 135, print.auc.cex = 2)
@

% \framebreak

% \begin{itemize}
  % \item $\text{pAUC} \in [0, c_2 - c_1]$.
  % \item The partial AUC can be corrected (see \href{http://journals.sagepub.com/doi/pdf/10.1177/0272989X8900900307}{McClish}), to have values between $0$ and $1$, where $0.5$ is non discriminant and $1$ is maximal: $$\text{pAUC}_\text{corrected} = \cfrac{1+\cfrac{\text{pAUC} - \text{min}}{\text{max} - \text{min}}}{2} $$
  % \item $\text{min}$ is the
% value of the non-discriminant AUC in the region
  % \item $\text{max}$ is the maximum possible AUC in the region
% \end{itemize}
\end{vbframe}

\endlecture
