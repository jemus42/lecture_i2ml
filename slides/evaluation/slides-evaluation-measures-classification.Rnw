<<set-parent, include = FALSE>>=
knitr::set_parent("../../style/preamble.Rnw")
@

<<setup, child="../../style/setup.Rnw", include = FALSE>>=
@

%! includes: evaluation-intro, classification-basicdefs

\lecturechapter{Evaluation: Simple Measures for Classification}
\lecture{Introduction to Machine Learning}


\begin{vbframe}{Labels vs Probabilities}

\lz
In classification we predict:

\lz
\begin{enumerate}
\item Class labels $\rightarrow \hh(\xv) = \hat{y}$
\item Class probabilites $\rightarrow \pikxh$
\end{enumerate}

\lz
$\rightarrow$ We evaluate based on those


\end{vbframe}

\begin{vbframe}{Labels: MCE}

The misclassification error rate (MCE) counts the number of incorrect predictions and presents them as a rate:

\[
MCE = \frac{1}{n} \sumin [\yi \neq \yih] \in [0;1]
\]

Accuracy is defined in a similar fashion for correct classifications:
\[
ACC = \frac{1}{n} \sumin [\yi = \yih] \in [0;1]
\]

\begin{itemize}
\item If the data set is small this can be brittle
\item The MCE says nothing about how good/skewed predicted probabilities are
\item Errors on all classes are weighed equally (often inappropriate)
\end{itemize}
\end{vbframe}





\begin{vbframe}{Labels: Confusion Matrix}

True classes in columns.\\
Predicted classes in rows.\\

\lz

<<echo=FALSE, comment=NA>>=
r = crossval("classif.naiveBayes", iris.task, show.info = FALSE)
m = calculateConfusionMatrix(r$pred, sums = TRUE)
# kable(m$result, booktabs = TRUE)
print(m)
@

\lz
We can see class sizes (predicted and true) and where errors occur.
\end{vbframe}



\begin{vbframe}{Labels: Confusion Matrix}
\textbf{In binary classification}
% % FIGURE SOURCE: No source
% \includegraphics[width=0.7\textwidth]{figure_man/roc-confmatrix1.png}

\begin{center}
\small
\begin{tabular}{cc|>{\centering\arraybackslash}p{7em}>{\centering\arraybackslash}p{8em}}
    & & \multicolumn{2}{c}{\bfseries True Class $y$} \\
    & & $+$ & $-$ \\
    \hline
    \bfseries Pred.     & $+$ & True Positive (TP)  & False Positive (FP) \\
              $\hat{y}$ & $-$ & False Negative (FN) & True Negative (TN) \\
\end{tabular}
\end{center}

\end{vbframe}




\begin{vbframe}{Labels: Costs}
We can also assign different costs to different errors via a cost matrix.
\[
  Costs = \meanin C[\yi, \yih]
\]

\underline{Example}:\\ 



Predict if person has a ticket (yes / no).\\ 
Should train conductor check ticket of a person?\\

\begin{columns}
\begin{column}{0.5\textwidth}


  \begin{tabular}{ll}
    \textbf{Costs:} & \\
    Ticket checking:& 3 EUR\\
    Fee for fare-dodging:& 40 EUR\\
    % Ticket price:& 10 EUR\\
  \end{tabular}
  
\end{column}
\begin{column}{0.5\textwidth} 

   \includegraphics[width=0.8\textwidth]{figure_man/conductor.jpg}
    {\tiny \url{http://www.oslobilder.no/OMU/OB.%C3%9864/2902}}
   
\end{column}
\end{columns}

\end{vbframe}


\begin{vbframe}{Labels: Costs}

Predict if person has a ticket (yes / no).\\ 

\begin{columns}
\begin{column}{0.3\textwidth} 

<<echo=FALSE, comment=NA>>=

set.seed(123)
n <- 100
y <- sample(c("yes", "no"), size = n, replace = TRUE, prob = c(0.9, 0.1))
dat <- data.frame(true = y, predicted = factor("no", levels = c("no", "yes")))
confmat <- as.matrix(ftable(predicted ~ true, data = dat))
costmat <- confmat
costmat[] <- c(-40+3, 3, 40, 0)


catf("Cost matrix C")
print(costmat)
cat(" ")
catf("Confusion matrix")
print(confmat)
cat(" ")
catf("Confusion matrix * C")
print(costmat * confmat)

cst_all <- sum(costmat * confmat)
@

\end{column}
\begin{column}{0.65\textwidth}


  \begin{tabular}{ll}
    \textbf{Costs:} & \\
    Ticket checking:& 3 EUR\\
    Fee for fare-dodging:& 40 EUR\\
    % Ticket price:& 10 EUR\\
  \end{tabular}
  \lz
  
  Our model says that we should not trust anyone and check the tickets of 
  all passengers.
  
  
  \begin{align*}
      Costs &= \meanin C[\yi, \yih] \\
      &= \frac{1}{\Sexpr{n}} \left( 
      \Sexpr{costmat[1,1]} \cdot \Sexpr{confmat[1,1]} + 
      \Sexpr{costmat[1,2]} \cdot \Sexpr{confmat[1,2]} + 
      \Sexpr{costmat[2,1]} \cdot \Sexpr{confmat[2,1]} +
      \Sexpr{costmat[2,2]} \cdot \Sexpr{confmat[2,2]} 
      \right) \\
      &= \frac{\Sexpr{cst_all}}{\Sexpr{n}} = \Sexpr{cst_all/n}
    \end{align*}
\end{column}

\end{columns}


\end{vbframe}


\begin{vbframe}{Probabilities: Brier Score}
Measures squared distances of probabilities from the true class labels:
\[
BS1 = \meanin \left( \pixih - \yi \right)^2
\]


\begin{itemize}
  \item Fancy name for MSE on probabilities
  \item Usual definition for binary case, $\yi$ must be coded as 0 and 1.
\end{itemize}

<<echo=FALSE, fig.width="0.8\\textwidth", fig.height=2.5>>=
phat = seq(0, 1, by = 0.02)
d = rbind(
  data.frame(phat = phat, BS = (1 - phat)^2, true.label = "1"),
  data.frame(phat = phat, BS = (0 - phat)^2, true.label = "0")
)
pl = ggplot(data = d, aes(x = phat, y = BS, col = true.label))
pl = pl + geom_line() + xlab(expression(hat(pi)(x)))
pl = pl + geom_vline(xintercept=0.5)
pl = pl + annotate(geom = "text", label = "right", x=0.1, y=0.1, col = pal_2[2])
pl = pl + annotate(geom = "text", label = "wrong", x=0.1, y=1.0, col = pal_2[1])
pl = pl + annotate(geom = "text", label = "wrong", x=0.9, y=1.0, col = pal_2[2])
pl = pl + annotate(geom = "text", label = "right", x=0.9, y=0.1, col = pal_2[1])
print(pl)
@


\framebreak

\[
BS2 = \meanin \sum_{k=1}^g \left( \pikxih - o_k^{(i)} \right)^2
\]
\begin{itemize}
  \item Original by Brier, works also for multiple classes
  \item $ o_k^{(i)} = [ \yi = k ] $ is a 0-1-one-hot coding for labels
  \item For the binary case, BS2 is twice as large as BS1, because in BS2 we sum the squared
    difference for each observation regarding class 0 \textbf{and} class 1, not only the true class.
\end{itemize}


\end{vbframe}

\begin{vbframe}{Probabilities: Log-Loss}
Logistic regression loss function, a.k.a. Bernoulli or binomial loss, $\yi$ coded as 0 and 1.
\[
LL = \meanin \left( - \yi \log(\pixih) - (1-\yi) \log(1-\pixih) \right)
\]
<<echo=FALSE, fig.width="0.8\\textwidth", fig.height=2.5>>=
library(grid)
phat = seq(0.01, 0.99, by = 0.01)
d = rbind(
  data.frame(phat = phat, LL = -log(phat), true.label = "1"),
  data.frame(phat = phat, LL = -log(1-phat), true.label = "0")
)
pl = ggplot(data = d, aes(x = phat, y = LL, col = true.label))
pl = pl + geom_line() + xlab(expression(hat(pi)(x)))
pl = pl + geom_vline(xintercept=0.5)
pl = pl + annotate(geom = "text", label = "right", x=0.1, y=0.1, col = pal_2[2])
pl = pl + annotate(geom = "text", label = "wrong", x=0.1, y=2.0, col = pal_2[1])
pl = pl + annotate(geom = "text", label = "wrong", x=0.9, y=2.0, col = pal_2[2])
pl = pl + annotate(geom = "text", label = "right", x=0.9, y=0.1, col = pal_2[1])
print(pl)
@
\begin{itemize}
  \item Optimal value is 0, \enquote{confidently wrong} is penalized heavily
  \item Multiclass version: $ LL = - \meanin \sum_{k=1}^g o_k^{(i)} \log(\pikxih) $
\end{itemize}
\end{vbframe}


\endlecture
