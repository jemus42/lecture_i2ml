\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}

\newcommand{\titlefigure}{figure_man/neunet.png}
\newcommand{\learninggoals}{
  \item \textcolor{blue}{XXX}
  \item \textcolor{blue}{XXX}
}

\title{Introduction to Machine Learning}
\date{}

\begin{document}

\lecturechapter{Examples of Hypothesis Spaces}
\lecture{Introduction to Machine Learning}

\begin{vbframe} {Hypothesis Spaces}

    Recall, the \textbf{hypothesis space} is the set of all admissible functions, that we have to pick a certain element from during learning / risk minimization.

$$
\Hspace := \{f: \Xspace \to \R^g ~~|~ f \text{ has a specific form}\}. 
$$

Often $f$ is parameterized by $\bm{\theta} \in \Theta$. We write $f(\xv) = f(\xv ~|~ \bm{\theta})$. 

\lz 

\textbf{Note:} If we are explicitly talking about hard classifiers outputting a discrete class, we write $h$ instead of $f$. 
  % If a model class can output discrete classes, scores, or probabilities (e.g. neural networks or ensemble methods), we just write $f$ to subsume all those cases.  


% (Often, the functions are is specified by a parameter $\bm{\theta} \in \Theta$.) % Then
%
% \lz
\end{vbframe}

\begin{vbframe}{Linear Models}

\begin{itemize}

  \item \textbf{Linear regression}: $f(\xv ~|~ \theta_0, \bm{\theta}) = \xv^T\bm{\theta} + \theta_0$ with $\bm{\theta} \in \R^p, \theta_0 \in \R$
  \begin{figure}
    \centering
      \scalebox{0.4}{\includegraphics{figure_man/linreg.png}}
  \end{figure}

  \item \textbf{Separating hyperplanes}: $h(\xv ~|~ \theta_0, \bm{\theta}) = \I[\xv^T\bm{\theta} - \theta_0 > 0]$%, $\bm{\theta} \in \R^p, \theta_0 \in \R$
  \begin{figure}
    \centering
      \scalebox{0.4}{\includegraphics{figure_man/sephyp.png}}
  \end{figure}
  \end{itemize}
\end{vbframe}

\begin{vbframe}{Trees and Ensembles}

\begin{itemize}
  \item \textbf{Decision trees}: $f(\xv) = \sum_{i = 1}^m c_i \I(\xv \in Q_i)$ 
    Where the $Q_i$ are an axis-aligned, rectangular partitioning of the input space
  \begin{figure}
    \centering
      \scalebox{0.6}{\includegraphics{figure_man/dectree.png}}
  \end{figure}

\item \textbf{Simple Ensembles}: $ f(\xv~|~\beta^{[j]}) = \sum_{j=1}^m \beta^{[j]} b^{[j]}(\xv)$  Where the $b^{[j]}(\xv)$ come from some base learner space $\mathcal{B}$.
  \begin{figure}
    \centering
      \scalebox{0.60}{\includegraphics{figure_man/ensembles.png}}
  \end{figure}

  \end{itemize}

\end{vbframe}

\begin{vbframe}{Neural Networks}

$f(\xv) = \tau \circ \phi \circ \sigma^{(h)} \circ \phi^{(h)} \circ \sigma^{(h-1)} \circ \phi^{(h-1)} \circ \ldots \circ \sigma^{(1)} \circ \phi^{(1)} (\xv)$

\begin{figure}
  \centering
    \scalebox{0.45}{\includegraphics{figure_man/neunet.png}}
\end{figure}

\begin{itemize}
  \item Consists of layers of simple computational \enquote{neurons} 
    % (there are $h + 1$ such layers in the formula above).
  \item Each neuron in a given layer performs a two-step computation: an affine linear transformation of its inputs, then a scalar non-linear activation. We can write this in vector notation for a complete layer:
  $$
    \phi^{(j)}(\bm{z}) = \bm{W}_j^\top \bm{z} + \bm{b}_j 
  $$
  The activation $\sigma^{(j)}$ applies componentwise the same non-linear function to its vector inputs (e.g. logistic or ReLU), while $\tau$ simply rescales for the final output (e.g. softmax). 
  Usually, $\sigma$ and $\tau$ contain no learnable parameters.
\end{itemize}

\end{vbframe}


\endlecture
\end{document}


