## Manual feature maps
```{r, include=FALSE, cache=FALSE}
ap = adjust_path(paste0(getwd(), "/figure"))
```

Note that all linear models can be turned into non-linear models
w.r.t. our original input space, if we opt to manually construct derived features
like higher order interactions or polynomial features.

Considering the given data we have no chance to separate them with a linear classifier:

```{r, echo=FALSE, out.width=".4\\textwidth", fig.align = 'center', fig.height=3, fig.width=3.7, message=FALSE}
# Data:
# -----
x1 = runif(200, -2, 2)
x2 = runif(200, -2, 2)

probs = ifelse (x1^2 + x2^2 > 1, 0.95, 0.05)
y = rbinom(n = 200, size = 1, prob = probs)

# Plot:
# -----
colBlue   = function (alpha) { rgb(135, 206, 255, alpha, maxColorValue = 255) }
colOrange = function (alpha) { rgb(255, 185,  15, alpha, maxColorValue = 255) }

cols.255 = c(colBlue(255), colOrange(255))[y + 1]
pchs = c(3, 6)[y + 1]

plot(x = x1, y = x2, col = cols.255, pch = pchs)
```

## Manual feature maps

Computing a new feature $z = x_1^2 + x_2^2$ gives us another view on the data
and we can separate them linearly in the new 3 dimensional space.

Afterwards we can map the linear boundary from 3 dimensions back into 2
dimensions which yields an ellipses.

\begin{center}
  \includegraphics[width=1.1\textwidth]{`r ap ("feature_map.png")`}
\end{center}

