## Properties: Single Linkage

```{r, echo=FALSE}
#Colors = colorspace::rainbow_hcl(3)
set.seed(0)
x = rbind(
  scale(matrix(rnorm(2*20, sd = 0.4), ncol = 2), center = c(1,1), scale = F),
  scale(matrix(rnorm(2*30, sd = 0.4), ncol = 2), center = -c(1,1), scale = F)
  )
x = rbind(x, matrix(rep(seq(-1,1, length.out = 10), each = 2), ncol = 2, byrow = TRUE))
#x = rbind(x, matrix(runif(2*10, min(x), max(x)), ncol=2))
d = dist(x)

tree.sing = hclust(d,method = "single")
tree.comp = hclust(d,method = "complete")
tree.avg = hclust(d,method = "average")
tree.cen = hclust(d,method = "centroid")

k = 3

labs.sing = cutree(tree.sing, k = k)
labs.comp = cutree(tree.comp, k = k)
labs.avg = cutree(tree.avg, k = k)
labs.cen = cutree(tree.cen, k = k)
```

Single linkage introduces the *chaining problem*:

  - Only one pair of points needs to be close to merge clusters.
  - A chain of points can expand a cluster over long distances.
  - Points within a cluster can be too widely spread and not dense enough.

```{r, echo = FALSE, fig.height=4, out.width="0.7\\textwidth"}
par(mfrow=c(1,2), mar = c(3,3,2,2))

plot(x,col=Colors[labs.sing], pch = 19, ylab = "", xlab = "", main = "single (chaining effect)")
plot(tree.sing, labels=F, hang=-1)
rect.hclust(tree.sing, k = k)#, border = Colors[1])

# http://www.sthda.com/english/articles/28-hierarchical-clustering-essentials/92-visualizing-dendrograms-ultimate-guide/
#fviz_dend(tree.sing, cex = 0.5, k = 3, # Cut in four groups
#  k_colors = "jco", rect = TRUE, rect.fill = TRUE, rect_border = "jco", lower_rect = 0)
```

## Properties: Complete Linkage

Complete linkage avoids chaining, but suffers from *crowding*: 

  - Merging is based on the furthest distance of point pairs from different clusters.
  - Points of two different clusters can thus be closer than points within a cluster. 
  - Clusters are dense, but too close to each other. <!-- and sensitive to outliers. -->

```{r, echo = FALSE, fig.height=4, out.width="0.7\\textwidth"}
par(mfrow=c(1,2), mar = c(3,3,2,2))

plot(x,col=Colors[labs.comp], pch = 19, ylab = "", xlab = "", main = "complete (crowding effect)")
plot(tree.comp, labels=F, hang=-1)
rect.hclust(tree.comp, k = k)#, border = Colors[1])

# http://www.sthda.com/english/articles/28-hierarchical-clustering-essentials/92-visualizing-dendrograms-ultimate-guide/
#fviz_dend(tree.sing, cex = 0.5, k = 3, # Cut in four groups
#  k_colors = "jco", rect = TRUE, rect.fill = TRUE, rect_border = "jco", lower_rect = 0)
```


## Properties: Average Linkage

- Average linkage is based on the average distance between clusters and tries to avoid crowding and chaining.
- Produces clusters that are quite dense and rather far apart.

```{r, echo=FALSE, fig.height=4.25, fig.width=7, out.width="0.8\\textwidth"}
par(mfrow=c(2,3), mar = c(3,3,2,2))

plot(x,col=Colors[labs.sing], pch = 19, ylab = "", xlab = "", main = "single (chaining effect)")
plot(x,col=Colors[labs.comp], pch = 19, ylab = "", xlab = "", main = "complete (crowding effect)")
plot(x,col=Colors[labs.avg], pch = 19, ylab = "", xlab = "", main = "average")
#plot(x,col=Colors[labs.cen], pch = 19, ylab = "", xlab = "", main = "centroid")

par(mar = c(1,4,2,1))
plot(tree.sing, labels=F, hang=-1)
rect.hclust(tree.sing, k = k)#, border = Colors[1])
plot(tree.comp, labels=F, hang=-1)
rect.hclust(tree.comp, k = k)#, border = Colors[1])
plot(tree.avg, labels=F, hang=-1)
rect.hclust(tree.avg, k = k)#, border = Colors[1])
#plot(tree.cen, labels=F, hang=-1)
#rect.hclust(tree.cen, k = k)#, border = Colors[1])
```

<!--
Average linkage isnâ€™t perfect, it has its own problems:

- It is not clear what properties the resulting clusters
  have when we cut an average linkage tree at given height $h$. Single
  and complete linkage trees each had simple interpretations.

- Results of average linkage clustering can change with a
  monotone increasing transformation of the distances.
  <!-- $d_{ij}$. I.e., if $h$ is such that $h(x) \leq h(y)$ whenever
  $x \leq y$, and we used dissimilarites $h(d_{ij})$ instead of
  $d_{ij}$, then we could get different answers 
  Depending on the context, this problem may be important or unimportant. 
  E.g., it could be very clear what distances should be used, or not. 

Note: results of single and complete linkage clustering are
unchanged under monotone transformations. (Exercise) -->

<!--
## Example of a change with monotone increasing transformation

![image](mono1.pdf) ![image](mono2.pdf)

\[fragile\]

## Hierarchical agglomerative clustering in R

The function hclust in the base package performs
hierarchical agglomerative clustering using single, complete, or average
linkage

E.g.,

    d = dist(x)
    tree.avg = hclust(d, method="average")
    plot(tree.avg)
-->

## Properties: Centroid Linkage

- Centroid linkage defines the distance based on **artificial data points** (the cluster centers), which produces dendrograms **with inversions**, i.e., the distance between the clusters to be merged can be smaller in the next step.

- In single, complete and average linkage, the distance between the clusters to be merged increases in each step. \
$\Rightarrow$ always produces dendrograms **without inversions**.

```{r, echo=FALSE, fig.width = 8, fig.height = 3.5, out.width="0.7\\textwidth"}
simple.data = data.frame(
  x = c(0,1,0.5),
  y = c(0,0,0.9)
)

#simple.data = as.data.frame(rbind(c(1,1), c(5,1), c(3,1+2*sqrt(3))))
par(mfrow = c(1,2), mar = c(4,4,1,1))
plot(simple.data, xlim = c(0, 1), ylim = c(0, 1), 
  xlab = "Dimension 1", ylab = "Dimension 2")
text(simple.data[1,], labels = 1, pos = 3)
text(simple.data[2,], labels = 2, pos = 3)
text(simple.data[3,], labels = 3, pos = 1)
centroid = colMeans(simple.data[1:2,])
points(centroid[1], centroid[2], col = "gray60", pch = 19)
text(centroid[1], centroid[2], labels = expression(C[12]), col = "gray60", pos = 4)
centroid = colMeans(simple.data[1:3,])
#points(centroid[1], centroid[2], col = "gray60", pch = 19)
#text(centroid[1], centroid[2], labels = expression(C[123]), col = "gray60", pos = 4)

agglo = hclust(dist(simple.data, method = "euclidean")^2, method = "centroid")
#cophenetic(agglo)
agglo$height = sqrt(agglo$height)

par(mar = c(2,4,1,1))
plot(as.dendrogram(agglo), main = "Cluster Dendrogram", ylab = "Height", ylim = c(0,1))
#rect.hclust(agglo, k = 2)
```

<!-- ## Properties -->

<!-- - Results of average and centroid linkage can change with a monotone increasing  -->
<!--   transformation of the distances, e.g. using the *squared euclidean distance*  -->
<!--   instead of the euclidean distance.  -->
<!-- - Results of single and complete linkage are insensitive to monotone increasing  -->
<!--   transformation of the distances. -->
<!-- - Centroid linkage produces inversions as it measures the distance based on *artificial data points* (cluster centers). -->
<!-- - In single, complete and average linkage there are no inversions. -->

  <!-- \newline
  Note: Results of single and complete linkage clustering will be unchanged. -->
    
