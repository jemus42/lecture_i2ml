## R Example with Iris Data

The data contains 150 leaf measurements for 3 flower species:

```{r, eval = FALSE}
pairs(iris[1:4], col = iris$Species)
```

```{r, echo=FALSE, out.width="0.9\\textwidth", fig.align="center", fig.height = 5.5, fig.width=9}
pairs(iris[1:4], pch = 19, col = iris$Species, oma = c(2,2,2,12))
legend(0.95, 1, levels(iris$Species), xpd = TRUE, horiz = F, xjust = 0.5,
       fill = unique(iris$Species), title = "Species")
```

## R Example with Iris Data

We now "forget" the real groups specified by the `Species` variable and try to find clusters based on the leaf measurements. 
<!--  Clustering techniques essentially try to formalise what human observers do 
so well in two or three dimensions (grouping by eye). -->

```{r, echo=FALSE, out.width="0.8\\textwidth", fig.align="center"}
pairs(iris[1:4], pch = 19)
```

## R Example with Iris Data

```{r, eval=FALSE}
# compute distance matrix
d.euclid = dist(iris[1:4], method = "euclidean")
# do clustering with average linkage
cl = hclust(d.euclid, method = "average")
plot(cl, labels = FALSE, hang = -1) # plot dendrogram
rect.hclust(cl, k = 3) # highlight the k = 3 groups
```

```{r, echo=FALSE, fig.width=12, fig.height=5}
par(mar = c(1,4,1,0))
d.euclid = dist(iris[1:4], method = "euclidean")
cl = hclust(d.euclid, method = "average")
plot(cl, labels = FALSE, hang = -1)
rect.hclust(cl, k = 3)
```

## R Example with Iris Data

We can extract the clustering assignments by cutting the dendrogram, e.g. using $k=3$ clusters:

```{r, eval = FALSE}
group = cutree(cl, k = 3) # get clusters assignments for k=3
pairs(iris[1:4], col = group) # plot clusters with different colors
```

```{r, out.width="0.75\\textwidth", fig.width=8, fig.height=5, fig.align="center", echo = FALSE}
group = cutree(cl, k = 3) 
pairs(iris[1:4], pch = 19, col = group) 
```
