## Properties of $K$-means

- $K$-means is based on computing the mean, which is sensitive to outliers and can only be computed for numerical data.

- The **within-cluster variation** is reduced in each iteration. 
  In R, the maximum number of iterations is specified by `iter.max`.

- The final result is typically not the best result that globally minimizes the **within-cluster variation**. \
  $\rightarrow$ would only be possible after trying all possible partitions!

- $K$-means can be restarted multiple times using `nstart`.
  The clustering with the smallest within-cluster variation is then selected as 
  the best solution.
  
## Properties of $K$-means

- $K$-means produces different clusters depending on the initial centers and always converges, e.g.:
<!-- In fact, it takes $\leq K^n$ iterations (why?) -->

```{r, echo=FALSE, fig.width=8, fig.height=4, fig.align="center", out.width="\\textwidth"}
set.seed(0)
x = rbind(
  scale(matrix(rnorm(2*20, sd = 0.4), ncol=2), center=c(1,1), scale = F),
  scale(matrix(rnorm(2*30, sd = 0.4), ncol=2), center=-c(1,1), scale = F)
  )
x = rbind(x, matrix(rep(seq(-1,1, length.out = 10), each = 2), ncol = 2, byrow = TRUE))
#x = rbind(x, matrix(runif(2*10, min(x), max(x)), ncol=2))
d = dist(x)

init.col = add.alpha("#000000", alpha = 0.5)
par(mfrow=c(1,3), mar = c(3,3,1,1))
for(i in 1:3) {
  rand = c(1, 25, 54)+i
  km1 = kmeans(x, centers = x[rand, ], nstart = 1, algorithm = "Lloyd")
  plot(x, pch = 19, col = km1$cluster, ylim = c(-1.5, 2))
  points(x[rand, 1], x[rand, 2], pch = 4, cex = 2, lwd = 2, col = init.col)
  if(i == 1) legend("topleft", pch = 4, pt.lwd = 2, pt.cex = 2, legend = "Initial Cluster Centers",
    col = init.col)
}

```

## Choice of $K$

- Many methods exist for choosing the number of clusters $K$ (there is no perfect solution).

- The easiest method is to apply $K$-means for different $K$ and plot the **within-cluster variation** for each number of $K$.
  
- The **within-cluster variation** always decreases with increasing number of clusters. 

- An **"elbow"** in the plot might indicate a useful solution.

```{r, echo=FALSE, fig.height=4.5, fig.align="center", out.width="0.7\\textheight"}
set.seed(1)
K = 8
wss = numeric(K)
for (k in 1:K) {
  km = kmeans(iris[,3:4], centers = k, nstart = 10, iter.max = 100, algorithm = "Lloyd")
  wss[k] = km$tot.withinss
}
par(mar = c(4,4,1,1))
plot(1:K, wss, type = "b", xlab = "K (number of clusters)", ylab = "within-cluster variation")
```
