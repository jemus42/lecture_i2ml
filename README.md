[![Build Status](https://travis-ci.com/compstat-lmu/lecture_i2ml.svg?token=yiXTK7TFAHiwv8cwsQus&branch=master)](https://travis-ci.com/compstat-lmu/lecture_i2ml)

# THIS IS THE DEVELOPMENT BRANCH!
- All changes for the next iteration will be accumulated here.
- At the end of the iteration all changes will be merged to the master branch.
- Use the pull-request workflow to add changes to this branch.

# Development instructions
todo see [issue](https://github.com/compstat-lmu/lecture_i2ml/issues/261).

# Introduction to Machine Learning (I2ML)

Main course site: https://compstat-lmu.github.io/lecture_i2ml/

Devel repo on Github: https://github.com/compstat-lmu/lecture_i2ml

## Course overview

The module offers an introductory and applied overview of ML regression and classification. 
This includes models such as linear regression, discriminant analysis, naive Bayes, decision trees and random forests, and their evaluation, with cross-validation and ROC analysis. 
At the end, we will briefly discuss and summarize more advanced techniques like hyperparameter optimization, model selection, nested resampling, and give some advice regarding practical work. 
The course is of an introductory nature and geared towards Bachelor's students.
It aims at a practical and operational understanding of the covered algorithms and models, with less emphasis on theory and formalism.
The accompanying exercises and tutorials are a mix of theoretical and practical assignments, the latter in `R`, for which we will often use the
[mlr](https://github.com/mlr-org/mlr) R package.

## Concept

The course is organized as a digital lecture, which should be as self-contained and enable self-study as much as possible. 
The major part of the material is provided as slide sets with lecture videos.
We have also prepared interactive tutorials where you can answer multiple choice questions, and learn how to apply the covered methods in `R` on some very short coding exercises. 
Our plan is to extend this practical self-study material over the next months and years.

## Requirements

- The course is targeted at *ML beginners* with a basic, university level, education in maths
- Simple linear algebra
- Simple calculus
- Simple probability theory
- Some stats knowledge, you should now what *mean*, *variance*, *bias*, etc., is
- (Linear) Modelling from a stats perspective can help, but is not required, we sometimes compare to that
- Working knowledge of R

## Help is appreciated and welcome!

A lecture like this will never be perfect and hopefully grow over the coming years. We strongly believe in open source and collaborative work. 
Approach us, if you think likewise and want help.

- Are you an ML expert and like the course, but have some feedback or consider extending it? 
  Write an email to Bernd and Fabian (see *Team* page).
- Are you a student taking the lecture - either at the LMU or online - and you spotted a typo, think we should rephrase something be or
  even would like to provide a new quiz question or coding example? Please consider providing a pull request. 
