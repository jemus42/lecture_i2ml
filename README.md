[![Build Status](https://travis-ci.com/compstat-lmu/lecture_i2ml.svg?token=yiXTK7TFAHiwv8cwsQus&branch=master)](https://travis-ci.com/compstat-lmu/lecture_i2ml)

# THIS IS THE DEVELOPMENT BRANCH!
- All changes for the next iteration will be accumulated here.
- At the end of the iteration all changes will be merged to the master branch.
- Use the pull-request workflow to add changes to this branch.

# Development instructions
todo see [issue](https://github.com/compstat-lmu/lecture_i2ml/issues/261).

# Introduction to Machine Learning (I2ML)

Main course site: https://compstat-lmu.github.io/lecture_i2ml/

Devel repo on Github: https://github.com/compstat-lmu/lecture_i2ml

## Content

The module offers an introductory and applied overview of "supervised" Machine Learning, i.e., regression and classification. 
This includes models such as linear regression, discriminant analysis, naive Bayes, decision trees and random forests, and their evaluation, with cross-validation and ROC analysis. 
More advanced techniques like hyperparameter optimization, model selection, nested resampling are summarized as well, accompanied by some advice regarding practical work.   
The course is of an introductory nature and geared towards Bachelor's students.
It's aimed at a practical and operational understanding of the covered algorithms and models, with less emphasis on theory and formalism.
The accompanying exercises, demos and tutorials are a mix of theoretical and practical assignments, the latter in **`R`**, for which we will often use the
[`mlr`](https://github.com/mlr-org/mlr) R package.

## Concept

The course is organized as a digital lecture, which should be as self-contained and enable self-study as much as possible. 
The major part of the material is provided as slide sets with lecture videos.
We have also prepared interactive tutorials where you can answer multiple choice questions, and learn how to apply the covered methods in `R` on some very short coding exercises. 
Our plan is to extend this practical self-study material over the next months and years.

## Prerequisites

The course is targeted at *ML beginners* with a basic, university level, education in maths:

- Basic linear algebra: vectors, matrices, determinants 
- Simple calculus: derivatives, integrals, gradients
- Some probability theory: probability, random variables, distributions
- Basic statistics knowledge: descriptive statistics, estimators.  (Linear) modelling from a statistics perspective can help, but is not required, we sometimes compare to that
- Working knowledge of **`R`**

## Help is appreciated and welcome!

We hope to continously improve and expand this course over the coming years. We strongly believe in open source and collaborative work. Please contact us if you think likewise and would like to contribute.

- Are you an ML expert and like the course, but have some feedback or consider extending it? 
  Write an email to Bernd and Fabian (see *Team* page).
- Are you a student taking the lecture - either at the LMU or online - and you spotted a typo, think we should rephrase something be or
  even would like to provide a new quiz question or coding example? Please consider providing a pull request. To do so, please check out the *devel* branch of the repo and add your fixes there. Writing an e-mail with suggested improvements is obviously very welcome as well!

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.

## Similar Projects

[Data Science in a Box](https://datasciencebox.org/) follows a similar philosophy as this course, with much more emphasis on learning R, doing data visualization and understanding more classical statistical inference methods (hypothesis tests, linear regression, etc.)
