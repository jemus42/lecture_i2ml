\documentclass{beamer}

\usepackage[orientation=landscape,size=a0,scale=1.4,debug]{beamerposter}
\mode<presentation>{\usetheme{mlr}}

\usepackage[utf8]{inputenc} % UTF-8
\usepackage[english]{babel} % Language
\usepackage{hyperref} % Hyperlinks
\usepackage{ragged2e} % Text position
\usepackage[export]{adjustbox} % Image position
\usepackage[most]{tcolorbox}
%\usepackage{nomencl}
%\makenomenclature
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{enumerate}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{colortbl}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{bm}

\input{basic-math.tex}
\input{basic-ml.tex}
\input{ml-bagging.tex}
\input{ml-boosting.tex}
\input{ml-trees.tex}


\title{I2ML :\,: CHEAT SHEET} % Package title in header, \, adds thin space between ::
\newcommand{\packagedescription}{ % Package description in header
	The \textbf{I2ML}: Introduction to Machine Learning course offers an introductory and applied overview of "supervised" Machine Learning. It is organized as a digital lecture.
}

\newlength{\columnheight} % Adjust depending on header height
\setlength{\columnheight}{84cm} 

\newtcolorbox{codebox}{%
	sharp corners,
	leftrule=0pt,
	rightrule=0pt,
	toprule=0pt,
	bottomrule=0pt,
	hbox}

\newtcolorbox{codeboxmultiline}[1][]{%
	sharp corners,
	leftrule=0pt,
	rightrule=0pt,
	toprule=0pt,
	bottomrule=0pt,
	#1}

\begin{document}
\begin{frame}[fragile]{}
\begin{columns}
	\begin{column}{.31\textwidth}
		\begin{beamercolorbox}[center]{postercolumn}
			\begin{minipage}{.98\textwidth}
				\parbox[t][\columnheight]{\textwidth}{
					\begin{myblock}{Performance}
                        \hspace*{1ex}
						\begin{codebox}
							\textbf{Performance estimation} refers to estimating performance on new data.
						\end{codebox}
					    \hspace*{1ex}
						\begin{codebox}
							\textbf{Different levels of randomness:}
						\end{codebox}
						\begin{enumerate}
                        \item The sample can be too small, then our estimator will be of high variance or if the sample could not be from the distribution of interest, then our estimator will be biased.
                        \item Many learning algorithms are stochastic. Example: Random forest, Stochastic gradient descent
                        \end{enumerate}
						\hspace*{1ex}
	
						\begin{codebox}
							 \textbf{Metrics: inner vs. outer loss}
						\end{codebox}
						Inner and outer loss should match. But as the outer loss is often numerically hard(er) to be handled, this is not always possible. So, approximate the outer loss.
						\hspace*{1ex}
				
					\end{myblock}
					%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
					\begin{myblock}{Simple Metrics}
					\begin{codebox}
							\textbf{Metrics for Label based prediction methods: }Accuracy, MCE, Costs,
						\end{codebox}
						\begin{codebox}
							 Confusion matrix, F1 measure, ROC curve  etc.
						\end{codebox}
						\hspace*{1ex}
						\begin{codebox}
						\textbf{Metrics for Probabilistic prediction methods: }Brier Score, Log-Loss 
                        \end{codebox}
                        \begin{codebox}
						etc. 
                        \end{codebox}
                        \\
                       \\ \includegraphics[width=1.05\columnwidth]{img/table_metric.PNG}
						\\
					\end{myblock}\vfill
				}
			\end{minipage}
		\end{beamercolorbox}
	\end{column}
	\begin{column}{.31\textwidth}
		\begin{beamercolorbox}[center]{postercolumn}
			\begin{minipage}{.98\textwidth}
				\parbox[t][\columnheight]{\textwidth}{
						\begin{myblock}{Train and Test Error}
						\begin{codebox}
							 \textbf{Training Error: }estimated by the averaging error over the same data
						\end{codebox}
						\begin{codebox}
							  set we fitted on
						\end{codebox}
						\hspace*{1ex}\textbf{Problems of training error: }
						\begin{enumerate}
                        \item Unreliable and overly optimistic estimator of future performance
                        \item There are interpolators - interpolating splines, interpolating Gaussian processes - they are not necessarily good as they will also interpolate the noise
                        \item Goodness-of-fit measures like $R^2$, likelihood, AIC, BIC etc are based on the training error
                        \end{enumerate}
                        \hspace*{1ex}
                        \begin{codebox}
							 \textbf{Test Error: }the test is a good way to estimate future performance,
						\end{codebox}
						\begin{codebox}
							 given that the test data is i.i.d. compared to the data we will see when
						\end{codebox}
							\begin{codebox}
						    we apply the model.
						\end{codebox}
						\hspace*{1ex}\textbf{Problems of test error:}
				        \begin{enumerate}
                        \item The estimator will suffer from high variance and be less reliable if the test set is too small
                        \item Sometimes the test set is large, but one of the two classes is small
                        \end{enumerate}
                        \hspace*{1ex}
						\begin{codebox}
				            \textbf{Holdout Splitting: }tools for estimating future performance, to put
						\end{codebox}
						\begin{codebox}
				            that next to our final model. All of the models produced during that
						\end{codebox}
						\begin{codebox}
				            phase of evaluation are intermediate results.
						\end{codebox}
						\hspace*{1ex}
					\\	\includegraphics[width=1\columnwidth]{img/test_error.png}
						\hspace*{1ex}		
					\end{myblock}
				}
			\end{minipage}
		\end{beamercolorbox}
	\end{column}
	\begin{column}{.31\textwidth}
		\begin{beamercolorbox}[center]{postercolumn}
			\begin{minipage}{.98\textwidth}
				\parbox[t][\columnheight]{\textwidth}{
				    \begin{myblock}{ }
							\begin{codebox}
							 \textbf{Generalization error: }is a measure of how accurately an algorithm is
						\end{codebox}
						\begin{codebox}
							  able to predict outcome values for previously unseen data
						\end{codebox}
						\hspace*{1ex}
						\begin{codebox}
							\textbf{Overfitting: }happens when our algorithm starts modelling patterns in
						\end{codebox}
						\begin{codebox}
							the data that are not actually true in the real world, e.g., noise in the
						\end{codebox}
						\begin{codebox}
						    training data
						\end{codebox}
						\hspace*{1ex}
						\begin{codebox}	
						\textbf{Avoiding Overfitting: }Use less complex models, get more and better
						\end{codebox}
						\begin{codebox}	
						 data, early stopping, regularization etc.
						\end{codebox}
				
						\\
						\end{myblock}
						\begin{myblock}{Resampling}
						The aim is to assess the performance of learning algorithm. Uses the data more efficiently and repeatedly splits in train and test, then average results.\\
						\begin{codebox}
							 \textbf{Cross-validation: }Split the data into $k$ roughly equally-sized partitions.
						\end{codebox}
						\begin{codebox}
						     Use each part once as test set and join the $k-1$ others for training
						\end{codebox}
						\begin{codebox}
						      obtain $k$ test errors and average.
						\end{codebox}
	
						\hspace*{1ex}
						\begin{codebox}
							 \textbf{Bootstrapping: }Randomly draw $B$ training sets of size $n$ with
						\end{codebox}
						\begin{codebox}
							   replacement from the original training set $\Dtrain$
						\end{codebox}
						\hspace*{1ex}
						\begin{codebox}
							 \textbf{Subsampling: }Repeated hold-out with averaging, a.k.a. monte-carlo 
						\end{codebox}
						\begin{codebox}
							  CV Similar to bootstrap, but draws without replacement
						\end{codebox}
						\hspace*{1ex}
                    \end{myblock}
				}
			\end{minipage}
		\end{beamercolorbox}
	\end{column}
\end{columns}
\end{frame}
\end{document}
