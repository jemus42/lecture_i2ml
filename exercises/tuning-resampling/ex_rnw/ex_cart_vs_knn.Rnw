\begin{enumerate}[a)]

  \item

    Suppose that we want to compare four different learners:

    \begin{tabular}{l|l}
      \textbf{Learner} & \textbf{Tuning required} \\
      \hline
      Logistic regression (\texttt{lm})      &  no \\
      CART  (\texttt{rpart})          &  yes \\
      $k$-NN (\texttt{kknn})            &  yes \\
      LDA (\texttt{lda})              &  no
    \end{tabular}
    
    For performance evaluation and subsequent comparison, we use 10-CV as 
    outer resampling strategy. 
    Within the inner tuning loop, applicable to CART and $k$-NN, we use 5-CV in 
    combination with random search, drawing 200 hyperparameter configurations 
    for each model. 
    Our measure of interest is the AUC.

    \begin{enumerate}[i)]
    
      \item How many models need to be fitted in total to conduct the final 
      benchmark?
      
      \item Giving the following benchmark result, which learner performs best? 
      Explain your decision.

        <<echo=FALSE, fig.width=5, fig.height=3>>=
        library(ggplot2)
        n_scores = 10
        set.seed(31415)
        df_bm = data.frame(
          model = c(
            rep("lm", n_scores*2),
            rep("rpart", n_scores*2),
            rep("kknn", n_scores*2),
            rep("lda", n_scores*2)),
          score = c(
            rnorm(n_scores, 0.85, 0.05), rnorm(n_scores, 0.2, 0.05),    # lm
            rnorm(n_scores, 0.9, 0.02), rnorm(n_scores, 0.25, 0.03),    # rpart
            rnorm(n_scores, 0.96, 0.04), rnorm(n_scores, 0.2, 0.05),    # kknn
            rnorm(n_scores, 0.93, 0.03), rnorm(n_scores, 0.14, 0.04)),  # lda
         measure = rep(
           c(rep("AUC", n_scores), rep("MMCE", n_scores)), 
           times = 4))
        ggplot(data = df_bm, aes(x = model, y = score, fill = measure)) + 
          geom_boxplot() +
          labs(x = "learner")
        @

    \end{enumerate}

  \item Recap briefly what is meant by the \textit{bias-variance trade-off} in 
  resampling.

  \item Are the following statements true or not? 
  Explain your answer in one sentence.
  \begin{enumerate}[i)]
      \item The bias of the generalization error estimate for 3-CV is 
      higher than for 10-CV.
      \item Every outer loss can also be used as inner loss, assuming standard 
      gradient-based optimization.
    \end{enumerate}
\end{enumerate}