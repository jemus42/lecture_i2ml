In this exercise we take a look at the leave-one-out-estimator. We will use a data independent model, so our data are all i.i.d. bernoulli($0.5$) distributed labels, $\{0,1\}$, $Y_1,\dots, Y_n$. Our (a bit strange) rule results after looking at the training  data always in a constant estimation. It works like that: If the training data consists of an odd number of $1$s it will estimate a $1$, otherwise a $0$.

\begin{enumerate}
\item What is the expected error of this rule?
\item Now we estimate this expected error on the training data with the leave-one-out-estimator. What expected value and variance has the result? How would you interpret this result?
\end{enumerate}
