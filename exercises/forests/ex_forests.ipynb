{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce3c119",
   "metadata": {},
   "source": [
    "***\n",
    "**Introduction to Machine Learning** <br>\n",
    "__[https://slds-lmu.github.io/i2ml/](https://slds-lmu.github.io/i2ml/)__\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e28232",
   "metadata": {},
   "source": [
    "# Exercise sheet 9: Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3447df",
   "metadata": {},
   "source": [
    "## Exercise 1: Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799c6ba",
   "metadata": {},
   "source": [
    "In this exercise, we briefly revisit why bagging is a useful technique to stabilize predictions. <br>\n",
    "For a fixed observation (x, y), show that the quadratic loss of the ensemble prediction $f^{[M]}(\\mathbf{x})$ is less than or equal to the average quadratic loss over individual base learner predictions $b^{[m]}(\\mathbf{x})$. You can assume an infinite theoretical ensemble and use EM to denote the expectation over its members. <br>\n",
    "\n",
    " **\\# Entering your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1953e2",
   "metadata": {},
   "source": [
    "## Exercise 2: Classifying `spam`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69a423",
   "metadata": {},
   "source": [
    "> a) Take a look at the spam dataset and shortly describe what kind of classification problem this is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652853e0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>R Hint:</b> access the corresponding task <code>?mlr3::mlr_tasks_spam</code> <br>\n",
    "<b>Python Hint:</b> read <a href=\"https://github.com/slds-lmu/lecture_i2ml/blob/master/exercises/data/spam.csv\"><code>spam.csv</code></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe26594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade12ec0",
   "metadata": {},
   "source": [
    "> b) Use a decision tree to predict `spam`. Re-fit the tree using two random subsets of the data (each comprising 60% of observations). How stable are the trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54797cc2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>R Hint:</b> Use <code>rpart.plot()</code> from the package <code>rpart.plot</code> to visualize the trees.</code> <br>\n",
    "<b>Python Hint:</b> : Use <code>from sklearn.tree import plot_tree</code> to visualize the trees.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dfb278",
   "metadata": {},
   "source": [
    "> c) Forests come with a built-in estimate of their generalization ability via the out-of-bag (OOB) error. <br>\n",
    ">> (i) Show that the probability for an observation to be OOB in an arbitrary bootstrap sample converges to $\\frac{1}{e}$. <br>\n",
    ">> (ii) Use the random forest learner (`R`: `classif.ranger`, `Python`: `RandomForestClassifier()`) to fit the model and state the out-of-bag (OOB) error.\n",
    "\n",
    " > **\\# (i) Entering your answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972a901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii) Entering your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b801377",
   "metadata": {},
   "source": [
    "> d) You are interested in which variables have the greatest influence on the prediction quality. Explain how to\n",
    "determine this in a permutation-based approach and compute the importance scorses for the `spam` data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fda8e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>R Hint:</b> use an adequate variable importance filter as described in <a href=\"https://mlr3filters.mlr-org.com/#variable-importance-filters\"><code>https://mlr3filters.mlr-org.com/#variable-importance-filters</code></a>. <br>\n",
    "<b>Python Hint:</b> : choose an adequate importance measure as described in <br>\n",
    "    <a href=\"https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\"><code>https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html</code></a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f656a3",
   "metadata": {},
   "source": [
    "## Exercise 3: Proximities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ed6ab",
   "metadata": {},
   "source": [
    "You solve the `wine` task, predicting the `type` of a wine – with $3$ classes – from a number of covariates. After\n",
    "training, you wish to determine how similar your observations are in terms of proximities. <br>\n",
    "For the following subset of the training data and the random forest model given below,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cddae9",
   "metadata": {},
   "source": [
    "> a)  find the terminal node of each tree the observations are placed in,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa342ec",
   "metadata": {},
   "source": [
    "> b) compute the observations’ pairwise proximities, and\n",
    "\n",
    "> **\\# Entering your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76d0f8",
   "metadata": {},
   "source": [
    "> c) construct a similarity matrix from these proximities in `R` resp. `Python`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d7e1f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>R Hint:</b> The model information was created with <code>ranger::treeInfo()</code>, which assigns observations with values\n",
    "larger than <code>splitval</code> to the right child node in each split. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering your code here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-i2ml",
   "language": "python",
   "name": "python-i2ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
