Assume your data follows the following law: $$\bm{y} = \bm{f} + \bm{\varepsilon}, \quad \bm{\varepsilon} \sim \mathcal{N}(\bm{0},\sigma^2 \bm{I}),$$
  with $\bm{f} = f(\bm{x}) \in \mathbb{R}^n$ being a realization of a Gaussian process (GP), for which we a priori assume $$f(\bm{x}) \sim \mathcal{GP}(m(\bm{x}),k(\bm{x},\bm{x}^\prime)).$$ $\bm{x}$ here only consists of 1 feature that is observed for $n$ data points.
  \begin{enumerate}
  \item Derive / define the prior distribution of $\bm{f}$.
  \item Derive the posterior distribution $\bm{f}|\bm{y}$.
  \item Derive the posterior predictive distribution $y_* | x_*, \bm{x}, \bm{y}$ for a new sample $x_*$ from the same data-generating process.
\item Implement the GP with squared exponential kernel, zero mean function and $\ls = 1$ from scratch for $n=2$ observations $(\bm{y},\bm{x})$. 
Do this as efficiently as possible by explicitly calculating all expensive computations by hand. Do the same for the posterior predictive distribution of $y_*$. Test your implementation using simulated data.
\end{enumerate}
