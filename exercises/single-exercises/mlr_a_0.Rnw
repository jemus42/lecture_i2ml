In preparing this course you already learned about \texttt{mlr}. If you need to refresh your knowledge you can find help at \url{https://mlr.mlr-org.com/} under 'Basics'.
\begin{enumerate}
\item[a)] How many performance measures do you already know? Try to explain some of them. How can you see which of them are available in \texttt{mlr}?
\item[b)] Use the \texttt{bh.task} regression task from \texttt{mlr} and split the data into $50\,\%$ training data and $50\,\%$ test data while training and predicting (i.\,e., use the \texttt{subset} argument of the \texttt{train} and \texttt{predict} function).
Fit a prediction model (e.\,g.\ knn) to the training set and make predictions for the test set.
\item[c)] Compare the performance on training and test data. Use the \texttt{performance} function.
\item[d)] Now use different observations (but still $50\,\%$ of them) for the training set. How does this affect the predictions and the error estimates of the test data?
\item[e)] Use 10 fold cross-validation to estimate the performance. Hint: Use the mlr functions \texttt{makeResampleDesc} and \texttt{resample}.
\item[f)] Now use nested resampling to fit the best knn model (try k from 1 to 10) on the \texttt{bh.task} and estimate the generalization error. Use the functions \texttt{makeParamSet}, \texttt{makeDiscreteParam}, \texttt{makeTuneControlGrid}, \texttt{makeResampleDesc}, \texttt{makeTuneWrapper} and \texttt{resample}. See also: \url{https://mlr.mlr-org.com/articles/tutorial/nested_resampling.html}.
\end{enumerate}
