\begin{enumerate}
\item 
\[
\text{Output of unit } i = f(\sum^n_{j=1} W_{j.i} \times activation_j)
\]
\begin{itemize}
\item First output unit input\\
$-0.3 \times 0.6 + 0.9 \times 0.8 = 0.54 \rightarrow f(0.54) = 0.632$

\item Second output unit input\\
$-0.6 \times 0.6 + -0.1 \times 0.8 = -0.44 \rightarrow f(-0.44) = 0.392$

\item Third output unit input\\
$0.4 \times 0.6 + 1.2 \times 0.8 = 1.2 \rightarrow f(1.2) = 0.769$
\end{itemize}

\item 

Error = target - output

\begin{itemize}
\item First output unit\\
$0.1 - 0.632 = -0.532$

\item Second output unit\\
$0.9 - 0.392 = 0.508$

\item Third output unit\\
$0.1 - 0.769 = -0.669$
\end{itemize}

\item

Each hidden node $j$ is responsible for some fraction of the error $Err_i$ of each of the output units $i$ to which it connects. Thus the $Err_i$ values are divided according to the strengths of the connection between the hidden node and the output nodes and are propagated back to the hidden nodes. Where a hidden node feeds-forward into more than $1$ output node the errors propagated back to it are summed: $Err_j = \sum^n_{i=1}W_{ji} \times Err_i$
\begin{itemize}
\item $Err_B = (-0.3 \times -0.532) + (-0.6 \times 0.508) + (0.4 \times -0.669) = 0.1596 + -0.3048 + -0.2676 = -0.4128$ 
\item $Err_C = (0.9 \times -0.532) + (-0.1 \times 0.508) + (1.2 \times -0.669) = -0.4788 + -0.0508 + -0.8028 = -1.3324$
\end{itemize}

\item 

The weight update rule is:
\[
W_{j,i} = W_{j,i} + (\alpha \times activation_j \times Err_i \times \frac{\partial\sigma(u_i)}{\partial u_i})
\]

With the sigmoidal function (See exercise 1):
\[
\sigma(u)' = (1 - \sigma(u)) \times \sigma(u)
\]

\begin{align*}
W_{B,D}=&W_{B,D} + (\alpha \times activation_B \times Err_D \times (1 - \sigma(u_D)) \times \sigma(u_D))\\
=& -0.3 + (0.25 \times 0.6 \times -0.532 \times 0.632 \times (1 - 0.632))\\
=& ...\\
=& -0.3186
\end{align*}


\end{enumerate}