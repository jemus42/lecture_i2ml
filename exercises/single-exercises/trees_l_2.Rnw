The fractions of the classes $k=1,\ldots,g$ in node $\mathcal{N}$ of a decision tree are $p(1|\mathcal{N}),\ldots,p(g|\mathcal{N})$.
Assume we replace the classification rule in node $t$

\begin{eqnarray*}
\hat{k}|\mathcal{N}=\arg\max_k p(k|\mathcal{N})
\end{eqnarray*}
with a randomizing rule, in which we draw the classes in one node from their estimated probabilities.

Derive an estimator for the misclassification rate in node $\mathcal{N}$.
What do you (hopefully) recognize?

The estimated probability, that an object of class $k$ is in node $\mathcal{N}$ is $p(k|\mathcal{N})$.
The estimated proportion, that an object from class $k$ and is predicted as a different class is:
$$p(k|\mathcal{N})\sum_{j \neq k} p(j|\mathcal{N}) = p(k|\mathcal{N}) (1 - p(k|\mathcal{N}))$$

Summing over all classes we get an estimator for probability of missclassifying
in node $\mathcal{N}$:

$$\hat{err_\mathcal{N}}= \sum_{k=1}^g p(k|\mathcal{N}) (1 - p(k|\mathcal{N})) = \sum_{k=1}^g p(k|\mathcal{N}) - \sum_{k=1}^g p(k|\mathcal{N})^2 = 1  - \sum_{k=1}^g p(k|\mathcal{N})^2 $$

This is exactly the Gini-Index, that CART uses for splitting the tree.
