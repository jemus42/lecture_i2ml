We need:

\begin{*align} 
P(Yellow \vert Yes), P(oblong \vert Yes), P(Imported \vert Yes) , P(Yellow \vert No) , P(oblong \vert No),  P(Imported \vert No) 
\begin{*end} 

and multiply them by P(Yes) and P(No) respectively. 

$n$ = 3, the number of training examples for which Banana ? = $b_j$

$n_i$ = number of examples for which Banana ? = $b_j$ and A = $a_i$

p = a priori estimate for $P(a_i \vert b_j)$

m = the equivalent sample size

\begin{*align} 
& P(a_i \vert b_j) = \frac{n_i + mp}{n+m} 
\begin{*end}

Our m value is arbitrary, (we will use m = 3) but consistent for all attributes. We are assuming no other information so, p = 1 / (number-of-attribute-values) = 0.5 for all of our attributes.

\begin{*align} 
P(Yellow \vert Yes) & = \frac{1+3*0.5}{3+3} = \frac{5}{12}  \\
P(Oblong \vert Yes) & = \frac{2+3*0.5}{3+3} = \frac{7}{12}\\
P(Imported \vert Yes) & = \frac{3+3*0.5}{3+3} = \frac{3}{4}\\
P(Yellow \vert No) & = \frac{2+3*0.5}{3+3} = \frac{7}{12} \\
P(Oblong \vert No) & = \frac{2+3*0.5}{3+3} = \frac{7}{12}\\
P(Imported \vert No) & = \frac{0+3*0.5}{3+3} = \frac{1}{4}\\
\begin{*end}

We have $P(Yes) = \frac{3}{8}$ and $P(No) = \frac{5}{8}$, so for $b_j$ = Yes, we have

$P(Yes) * P(Yellow  \vert  Yes) * P(Oblong  \vert  Yes) * P(Impoted \vert Yes) = \frac{3}{8} * \frac{5}{12} *\frac{7}{12} * \frac{3}{4} \approx 0.068 $

Ans for for $b_j$ = No, we have

$P(No) * P(Yellow  \vert  No) * P(Oblong  \vert  No ) * P(Impoted \vert No ) = \frac{5}{8} * \frac{7}{12} *\frac{7}{12} * \frac{1}{4} \approx  0.053 $

Since 0.068 $\geq$ 0.053, our example gets classified as ’YES’