%x <- c(4,7,9,4,6,7,9,7,8)
%y <- c(6,3,8,9,5,8,7,6,5)
%z <- as.factor(c(1,1,1,0,0,0,0,2,1))

Let the 2D feature vectors in the following figure be with two different class labels (triangles
and circles). Classify the point (7,6) - represented by a square in the picture - with
a k-nearest neighbor classifier. Distance function should be the L1 norm (Manhattan distance). 
As a decision rule, you use the unweighted number of the individual classes in the k-next
Neighbor Quantity, i.e. the point is assigned to the class that represents most k-nearest neighbors.

(a) k = 3

(b) k = 5

(c) k = 7


%d3 = c(5,7,9,7)
%v3 = c(6,8,6,4)

%d5 = c(4,7,10,7)
%v5 = c(6,9,6,3)

%d7 = c(3,7,10,10,7)
%v7 = c(6,10,7,5,2)



%require(ggplot2)
%qplot(x, y, shape = z,size=I(6),col=z)+ theme(legend.position="none") + 
%scale_x_continuous(minor_breaks = seq(0, 10, by = 1),breaks = seq(0, 10, by = 1),limits=c(0,10)) +
%scale_y_continuous(minor_breaks = seq(0, 10, by = 1),breaks = seq(0, 10, by = 1),limits=c(0,10)) +
%annotate("polygon", x=d7,y=v7, alpha=0.2, fill="red") 



\includegraphics[width=100mm]{knn_manh.pdf}
  
