Summarize the logistic regression model (shortly!). Show that the decision boundaries, which are defined as the area where the estimated probability for class 1 is exactly $0.5$, is always a hyperplane between both classes.

Logistic regression is a classification model, that estimates posterior probabilities by linear functions in $x$.
For a binary classification problem the model can be written as:\\

$$
\log\frac{\P(y = 1 | x)}{\P(y = 0 | x)} = \beta^T x
$$
We want to model the probability for class 1:
$$
\P(y = 1 | x) = \frac{\exp(\beta^T x)}{1 + \exp(\beta^T x)} = \frac{\exp(f(x))}{1 + \exp(f(x))}
$$
Let $\P(y = 1 | x) = \frac{1}{2}$, it follows:
\begin{eqnarray*}
\frac{1}{2}&=&  \frac{\exp(f(x))}{1 + \exp(f(x))}\\
\frac{1}{2} + \frac{1}{2} \cdot \exp(f(x)) &=& \exp(f(x)) \\
\frac{1}{2}&=& \exp(f(x)) - \frac{1}{2}\exp(f(x)) \\
1&=& \exp(f(x))\\
\Longleftrightarrow f(x) &=& \log(1)\\
\Longleftrightarrow \beta^T X &=& 0\\
\end{eqnarray*}
