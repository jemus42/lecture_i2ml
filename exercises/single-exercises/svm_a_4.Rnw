Write your own soft-margin SVM.

This is not too simple, so please note:

\begin{itemize}
\item Use the regularized-risk-minimization-formulation, i.e. an optimization criterion without constraints.

\item No kernels, just a linear SVM.

\item Optimize with a adequate method in `optim`. It doesn't have to be the best method, but think about which possibilities are good.

\item Compare your implementation with `kernlab`. Are your results similar? The comparison is a bit difficult because `kernlab` uses the dual.
\begin{itemize}
\item Switch off the automatic data scaling.
\item Compare the decicion values of `ksvm` and your method.
\item If you want to compare the w-vector, calculate it from your `ksvm` model `m` and your design matrix `X`:
\item Use the following datasets
<<eval=FALSE>>=
coef(m)[[1]] %*% X[SVindex(m), ]
@
<<eval=FALSE>>=
data = mlbench.twonorm(n = 100, d = 2)
data = as.data.frame(data)
@

\end{itemize}

\end{itemize}
