\begin{enumerate}[a)]

  \item We face a \textbf{supervised regression} task: we definitely need 
  labeled training data to infer a relationship between cars' attributes and 
  their prices, and price in EUR is a continuous target (or quasi-continuous, 
  to be exact -- as with all other quantities, we can only measure it with 
  finite precision, but the scale is sufficiently fine-grained to assume 
  continuity). \textbf{Prediction} is definitely the goal here, however, it 
  might also be interesting to examine the explanatory contribution of each 
  feature.
  
  \item Target variable and potential features: \\
  
  \begin{tabular}{l|l|l}
    \textbf{Variable} & \textbf{Role} & \textbf{Data type} \\ \hline
    Price in EUR & Target & Numeric \\ \hline
    Age in days & Feature & Numeric \\ \hline
    Mileage in km & Feature & Numeric \\ \hline
    Brand & Feature & Categorical \\ \hline
    Accident-free y/n & Feature & Binary \\ \hline
    \dots & \dots & \dots
  \end{tabular}
  
  \item Both features and target are numeric and (quasi-)continuous. It is also 
  reasonable to assume non-negativity for the features, such that we 
  obtain $\Xspace = (\R_{0}^{+})^2$, with $\xi = (x_{\text{age}}, 
  x_{\text{mileage}})^{(i)} \in \Xspace$ for $i = 1, 2, \dots, n$. 
  As the standard LM does not impose any 
  restrictions on the target, we have $\Yspace = \R$, though we would probably 
  discard negative predictions in practice.
  
  \item Hypothesis space:
  
  \begin{flalign*}
    \Hspace &= \{ f: (\R_{0}^{+})^2 \rightarrow \R ~|~ 
    \fx = \theta_0 + \thetab^T \xv, ~ (\theta_0, \thetab) \in \R^3 \} \\
    &=  \{ f: (\R_{0}^{+})^2 \rightarrow \R ~|~ 
    \fx = \theta_0 + \theta_{\text{age}} x_{\text{age}} + 
    \theta_{\text{mileage}} x_{\text{mileage}}, ~ (\theta_0, 
    \theta_{\text{age}}, \theta_{\text{mileage}}) \in \R^3 \},
  \end{flalign*}
  
\end{enumerate}