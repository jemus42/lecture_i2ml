Assume the following (noisy) data-generating process: 
$y = 0.5 + 0.4 \cdot \sin(2 \pi x) + \epsilon$ with $\epsilon \sim N(0, 0.1).$

<<echo=FALSE, message=FALSE, fig.align="center", fig.height = 2, fig.width=5>>=
set.seed(1L)
x <- seq(0L, 1L, length.out = 30L)
eps <- rnorm(length(x), 0L, 0.1)
y <- 0.5 * sin(2 * pi * x) + eps
ggplot2::ggplot(data.frame(x = x, y = y), ggplot2::aes(x, y)) + 
  ggplot2::geom_point() +
  ggplot2::theme_bw()
@

\begin{enumerate}[a)]
  \item We decide to model the data with a cubic polynomial (including intercept 
  term, no interactions). State the corresponding hypothesis space.
  \item Demonstrate that this hypothesis space is but a parametrized family of 
  curves by plotting in R curves for 5 different models belonging to the 
  considered model class.
  \item State the corresponding parameter space.
  \item State the empirical risk w.r.t. $\thetab$ for a member of our hypothesis 
  space. Use $L2$ loss and be as explicit as possible.
  \item We can minimize this risk using gradient descent. In order to make this 
  somewhat easier, we will denote our transformed feature matrix 
  % (i.e., 
  % $\begin{bmatrix} x^0 & x^1 & x^2 & x^3 \end{bmatrix}$) 
  % by $\tilde \Xmat$, 
  enabling us to express our model by $\tilde \Xmat \thetab$ (note that our 
  model is still linear in its parameters, even if $\Xmat$ has been transformed 
  in a non-linear manner). 
  Derive the gradient of the empirical risk w.r.t. $\thetab$, which is 
  multiplied by $- \alpha$ to update the current parameter vector 
  $\thetab^{[t]}$.
  \item Assemble the above used components to formalize the HRO setting for
  this specific task.
\end{enumerate}