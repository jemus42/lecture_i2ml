\begin{enumerate}[a)]

    \item From the lecture we can retrieve the empirical risk function:

\[
R_{emp}(\theta) = \frac{1}{n}(X\theta - Y)^2
\]

A gradient descend step is given by:
\[
\theta^{[t+1]} =\theta^{[t]} - \alpha \frac{\partial}{\partial\theta}R_{emp}(\theta^{[t]})
\]

Therefore we need the derivative of $R_{emp}$:

\[
\frac{\partial}{\partial\theta}R_{emp}(\theta^{[t]}) =  \frac{2}{n}X^T[X\theta^{[t]} - y]
\]

\begin{align*}
    \frac{\partial}{\partial\theta}R_{emp}(\theta^{[0]}) &= \frac{2}{6} \begin{bmatrix}
        1 & 1 & 1 & 1 & 1 & 1 \\
        0.56 & 0.22 & 1.7 & 0.63 & 0.36 &  1.2   \\
        \end{bmatrix}\left(\begin{bmatrix}
            1 & 0.56  \\
            1 & 0.22  \\
            1 & 1.7  \\
            1 & 0.63  \\
            1 & 0.36  \\
            1 & 1.2  \\
            \end{bmatrix}\begin{bmatrix}0 \\ 0\end{bmatrix} - \begin{bmatrix}
                160  \\
                150  \\
                175  \\
                185  \\
                165  \\
                170  \\
                \end{bmatrix} \right) \\ &=
    -\frac{1}{3} \begin{bmatrix}
    1 & 1 & 1 & 1 & 1 & 1 \\
    0.56 & 0.22 & 1.7 & 0.63 & 0.36 &  1.2   \\
    \end{bmatrix} \begin{bmatrix}
        160  \\
        150  \\
        175  \\
        185  \\
        165  \\
        170  \\
        \end{bmatrix} \\
        &=
        \begin{bmatrix} -335 \\ -266.683\end{bmatrix}
\end{align*}

\begin{align*}
    \theta^{[1]} &= \begin{bmatrix}0 \\ 0\end{bmatrix} - 0.1  \begin{bmatrix} -335 \\ -266.683\end{bmatrix} =  \begin{bmatrix} 33.5 \\ 26.6683\end{bmatrix}
\end{align*}

We can easily verify the computation in R:

<<echo=TRUE, fig.align="center", fig.height = 3, fig.width=5>>=
r_emp_derivative = function(theta_t, X, y) {
  2 / nrow(X) * (t(X) %*% (X %*% theta_t - y))
}
@

<<echo=TRUE, fig.align="center", fig.height = 3, fig.width=5>>=
grad_desc_step = function(theta_t, X, y, alpha) {
  theta_t - alpha * r_emp_derivative(theta_t, X, y)
}
@

Note that $X$ is a matrix with $X = [1\;x]$, as
\[
f(X) = \theta X = \theta_0 1_{n} + \theta_1 x
\]

<<echo=TRUE, fig.align="center", fig.height = 3, fig.width=5>>=
small_x = c(0.56, 0.22, 1.7, 0.63, 0.36, 1.2)
X = cbind(1, small_x)
y = c(160, 150, 175, 185, 165, 170)

grad_desc_step(c(0, 0), X, y, 0.1)
@

\item

<<echo=TRUE, fig.align="center", fig.height = 3, fig.width=5>>=
grad_desc = function(small_x, y, iterations, alpha = 0.1) {
  X = cbind(1, small_x)
  theta_t = c(0, 0)
  # Repeat for n steps
  for (i in 1:iterations) {
    theta_t = grad_desc_step(theta_t, X, y, alpha)
  }
  return(theta_t)
}
@

\item

<<echo=TRUE, fig.align="center", fig.height = 3, fig.width=5>>=
iterations = c(1, 25, 50, 100, 250, 500, 750, 1000)
theta_hat = sapply(iterations, function(z) grad_desc(small_x, y, z))
predictions = cbind(iterations, t(theta_hat))
colnames(predictions) = c("iterations", "theta_0", "theta_1")

predictions
@

Looking at exercise 2 of the previous sheet, one can see, that
$\hat{\theta_0} = 158.73954$ and $\hat{\theta_1} = 11.25541$. We know, that
this is a local minimum. The values from the gradient descent only slowly
approaches the local minimum. As we can see, the predicted $\hat{\theta}_{\mathrm{grad\_desc}}$ of the
\texttt{grad\_desc} function only coincides with $\hat{\theta}_{\mathrm{analytical}}$
for a large number of iterations. Since the starting value $\theta^{[0]} = (0 ,0)$
is not close to the minimum, it takes some steps to get a good approximation.

\end{enumerate}
