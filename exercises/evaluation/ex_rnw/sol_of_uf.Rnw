\begin{enumerate}[a)]
  \item NB: we can only state tendencies here -- performance strongly depends 
  on the specific data situation.
  \begin{enumerate}[i)]
    \item We expect the flexible learner to perform better because it covers 
    a large number of hypotheses and we have enough data to tell them apart, 
    so there is little risk of overfitting, while the inflexible learner might 
    underfit.
    \item With a flexible learner we might quickly run into overfitting
    here. The data situation, which we frequently encounter in biostatistics 
    (e.g., genomics data), creates a high-dimensional and sparsely populated 
    input space with a training distribution that is easy to overfit.
    Therefore, a low-degree polynomial should fare better (but note that 
    it is not immune to overfitting either in this challenging setting).
    Some sort of feature selection could be advisable first.
    \item The inflexible learner will likely underfit here, so the 
    flexible variant can be expected to perform better.
    \item The flexible learner might 
    interpolate between the noisy training samples, creating a wiggly curve that 
    generalizes poorly, so we expect better performance from a less complex 
    learner.
  \end{enumerate}
  \item Overfitting and underfitting are always connected to a 
  particular fixed \textit{model}, even though attributes of the underlying 
  hypothesis space typically influence the tendency toward one or the other 
  behavior, as we have seen in the previous question.
  In order to understand this, think of a classification problem with linearly 
  separable data.
  Applying a QDA learner, which is able to learn more complex decision 
  boundaries, poses a risk of overfitting with the chosen model, but the degree 
  of overfitting depends on the model itself.
  In theory, the QDA learner is free to set equal covariances for the 
  Gaussian class densities, amounting to LDA and \textit{not} overfitting the 
  data.
  % A QDA model with distinctly different covariances, on the other hand, will 
  % probably invoke overfitting.
  Under- and overfitting are therefore properties of a specific model and not 
  of an entire learner.
  
  A common strategy is to choose a rather flexible model class and encourage 
  simplicity in the actual model by \textit{regularization} (e.g., take a 
  higher-degree polynomial but drive as many coefficients a possible toward 
  zero, which you might know as LASSO regression).
  
  \item That will be hardly possible.
  Recall how we defined the two variants of data fit:
  $$UF(\fh, L) = GE(\fh, L) - GE(f^\ast, L)$$
  $$OF(\fh, L) = GE(\fh, L) - \riske(\fh, L)$$
  In order to avoid underfitting completely we would need to always find the 
  universally loss-optimal model across arbitrary hypothesis spaces (the 
  so-called \textit{Bayes-optimal} model), which is obviously not something we 
  can hope to achieve in general.
  Zero overfitting would mean to exactly balance theoretical generalization 
  error and empirical risk, but the way empirical risk minimization is designed, 
  our model will likely fare a bit worse on unseen test data.
  
  In practice we will always experience these phenomena to some degree and 
  finding a model that trades them off well is the holy grail in machine 
  learning.
\end{enumerate}