\begin{itemize}
\item The training performance is too optimistic  (mmce of 0), because the mmce is higher on new data.
\item The test performance is unbiased (if the final model is only trained on the training data), but it depends on the split, as can be seen in the CV folds: 
  Each CV fold represents a training test split and the mmce measure varies between folds.
\item The CV estimate averages over the different splits and gives an slightly pessimistic, more robust estimate.
\item The CV estimate is preferable over the other two, but more computationally expensive.
\end{itemize}
