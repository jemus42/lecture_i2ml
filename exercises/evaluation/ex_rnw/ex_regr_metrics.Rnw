Imagine you work for a data science start-up and sell turn-key 
statistical models.
Based on a set of training data, you develop a regression model to predict a 
customer's legal expenses from the average monthly 
number of indictments brought against their firm. 

  <<echo=FALSE, message=FALSE>>=

set.seed(123)
x_train <- seq(10, 15, length.out = 50)
y_train <- 10 + 3 * sin(0.15 * pi * x_train) + rnorm(length(x_train), sd = 0.5)
data_train <- data.frame(x = x_train, y = y_train)

@

\begin{enumerate}[a)]
  \item Due to the financial sensitivity of the situation, you opt for a very 
  flexible learner that fits the customer's data ($\ntrain = 50$ observations) 
  well, and end up with a degree-21 polynomial (blue, solid).
  Your colleague is skeptical and argues for a much simpler linear learner
  (gray, dashed).
  Which of the models will have a lower empirical risk if standard $L2$ loss 
  is used?
  <<echo=FALSE, message=FALSE, fig.align="left", fig.height=4, fig.width=8>>=

ggplot2::ggplot(data_train, ggplot2::aes(x = x, y = y)) +
  ggplot2::geom_point() +
  ggplot2::geom_smooth(method = lm, formula = y ~ poly(x, 21), se = FALSE) + 
  ggplot2::geom_smooth(
    method = lm, formula = y ~ x, se = FALSE, col = "darkgray", linetype = 2L) + 
  ggplot2::labs(
    x = "average number of indictments per month", 
    y = "legal expenses in million EUR") +
  ggplot2::theme_classic()
@
  \item Why might evaluation based on training error not be a good idea here?
  \item Evaluate both learners on the following test data ($\ntest = 10$), using 
  \begin{enumerate}[i)]
    \item mean squared error (MSE), and
    \item mean absolute error (MAE).
  \end{enumerate}
  State your performance assessment and explain potential differences.
  
  (Hint: use \texttt{R} if you don't feel like computing a degree-21 polynomial 
  regression by hand.)
    <<echo=TRUE, message=FALSE>>=

set.seed(123)
x_train <- seq(10, 15, length.out = 50)
y_train <- 10 + 3 * sin(0.15 * pi * x_train) + rnorm(length(x_train), sd = 0.5)
data_train <- data.frame(x = x_train, y = y_train)

set.seed(321)
x_test <- seq(10, 15, length.out = 10)
y_test <- 10 + 3 * sin(0.15 * pi * x_test) + rnorm(length(x_test), sd = 0.5)
data_test <- data.frame(x = x_test, y = y_test)

@
\end{enumerate}


