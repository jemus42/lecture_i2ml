\begin{figure}[h!]
\centering
\includegraphics[width=0.5\textwidth]{../../Aufgaben/NNet.png}
\end{figure}

The figure shows a 2-layer neural network that is currently processing the training vector $[1.0, 0.9, 0.9]$ which has an associated target vector $[0.1, 0.9, 0.1]$. 
Given that the output from unit $B$ is $0.6$ and from $C$ is $0.8$, and assuming that the activation function used at all nodes in the network is the sigmoid function 
\[
\sigma(u) = \frac{1}{1+e^{-u}}
\]

\textbf{Note:} This is a 3-class classification problem \textbf{without} softmax and corss-entropy. Every output is transformed via the sigmoid function and we are minimizing the SSE. This is an alternative way of fitting a neural network for classification.

\begin{enumerate}
\item Calculate the actual output vector (to 3 decimal places).
\item Calculate the error for each output unit.
\item Calculate the error for each hidden unit $B$ and $C$.
\item Calculate the new weight for the connection from unit $B$ to the output $D$ after the training example has been processed. Use a learning rate of $\alpha = 0.25$.
\end{enumerate}