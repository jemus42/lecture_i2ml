Logistic regression is a classification model, that estimates posterior probabilities $\pi(x)$ by linear functions in $x$.
For a binary classification problem the model can be written as:\\

$$
\hat{y} = 1 \ \ \Leftrightarrow \ \ \pi(x) = \frac{1}{1 + \exp(-x^T\theta)} \geq a
$$

For the decision boundary we have to set $\pi(x) = a$. Solving this equation for $x$ yields:

\begin{align*}
&\frac{1}{1 + \exp(-x^T\theta)} = a \\
\Leftrightarrow\ & 1 + \exp(-x^T\theta) = a^{-1} \\
\Leftrightarrow\ & \exp(-x^T\theta) = a^{-1} - 1 \\
\Leftrightarrow\ & \exp(-x^T\theta) = a^{-1} - 1 \\
\Leftrightarrow\ & -x^T \theta = \log(a^{-1} - 1) \\
\Rightarrow\ & x^T \theta = -\log(a^{-1} - 1) \\
\end{align*}

For $a = 0.5$ we get:

$$
x^T \theta = -\log(0.5^{-1} - 1) = -\log(2 - 1) = -\log(1) = 0
$$
