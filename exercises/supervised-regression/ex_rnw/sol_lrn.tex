\begin{enumerate}[a)]

  \item Model classes representing a certain \textbf{hypothesis} are stored in 
  \texttt{learner} objects. Before training them on actual data, they just 
  contain information on the functional form of $f$.
  Once a learner has been trained we can examine the parameters of the 
  resulting model.
  The empirical \textbf{risk} can be assessed after training by several 
  performance measures (e.g., based on $L2$ loss).
  \textbf{Optimization} happens rather implicitly as \texttt{mlr3} only acts as 
  a wrapper for existing implementations and calls package-specific 
  optimization procedures.
  
  \item
\begin{Schunk}
\begin{Sinput}
> library(mlr3)
> mlr3::tsk("iris")
\end{Sinput}
\begin{Soutput}
<TaskClassif:iris> (150 x 5)
* Target: Species
* Properties: multiclass
* Features (4):
  - dbl (4): Petal.Length, Petal.Width, Sepal.Length, Sepal.Width
\end{Soutput}
\end{Schunk}
  We obtain the following information:
  \begin{itemize}
    \item \texttt{iris} is a classification task.
    \item It has 150 observations of 5 variables, one of which is the 
    target.
    \item The target feature \texttt{Species} contains more than 2 classes.
    \item We have 4 features, all of them floating numbers (\texttt{dbl}).
  \end{itemize}
  If necessary, we can specify further task attributes. For example, we might 
  have one feature that merely stores unique identifiers for each observation. 
  \texttt{mlr3} allows us to set the \textit{role} of this variable to an 
  ID variable. We can also assign roles of weighting or stratifying variables in 
  analogous fashion. Other task attributes include the number of missing values 
  per feature and the so-called \textit{backend} (the raw data we created our 
  task from -- besides using pre-specified tasks like \texttt{iris} it is 
  possible convert any data of suitable format to a task).

\end{enumerate}
