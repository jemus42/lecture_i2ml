\begin{enumerate}[a)]
  
  \item Let the two-dimensional feature vectors in the following figure be 
  instances of 
  two different classes (triangles and circles). 
  Classify the point (7, 6) -- represented by a square in the picture -- with
  a $k$-NN classifier using $L1$ norm (Manhattan distance):

  $$d_\text{Manhattan}(\xv, \xtil) = \sumjp |x_j - \tilde{x}_j|.$$
  
  As a decision rule, use the unweighted number of the individual classes in the 
  $k$-neighborhood, i.e., assign the point to the class that represents most 
  neighbors.

  \begin{enumerate}[i)]
    \item $k = 3$
    \item $k = 5$
    \item $k = 7$
  \end{enumerate}

<<echo=FALSE, message=FALSE, fig.align="left", fig.height = 2, fig.width=2>>=
x <- c(4, 7, 9, 4, 6, 7, 9, 7, 8)
y <- c(6, 3, 8, 9, 5, 8, 7, 6, 5)
z <- as.factor(c(1, 1, 1, 0, 0, 0, 0, 2, 1))

d3 = c(5, 7, 9, 7)
v3 = c(6 , 8, 6, 4)

d5 = c(4, 7, 10, 7)
v5 = c(6, 9, 6, 3)

d7 = c(3, 7, 10, 10, 7)
v7 = c(6, 10, 7, 5, 2)

library(ggplot2)
qplot(x, y, shape = z, col = z) + 
  theme_bw() +
  theme(legend.position="none") +
  scale_x_continuous(
    minor_breaks = seq(0, 10, by = 1),
    breaks = seq(0, 10, by = 1), 
    limits = c(0, 10)) +
  scale_y_continuous(
    minor_breaks = seq(0, 10, by = 1), 
    breaks = seq(0, 10, by = 1),
    limits = c(0, 10))
@

  \item Now consider the same constellation but assume a regression problem 
  this time, where the circle-shaped points have a target value of 2 and the 
  triangles have a value of 4.
  
  Again, predict for the square point (7, 9), using both the \textit{unweighted} 
  and the \textit{weighted} mean in the neighborhood (still with Manhattan 
  distance).
  
  \begin{enumerate}[i)]
    \item $k = 3$
    \item $k = 5$
    \item $k = 7$
  \end{enumerate}

\end{enumerate}
