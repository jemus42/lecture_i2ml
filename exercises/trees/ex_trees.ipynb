{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8951982b",
   "metadata": {},
   "source": [
    "***\n",
    "**Introduction to Machine Learning** <br>\n",
    "__[https://slds-lmu.github.io/i2ml/](https://slds-lmu.github.io/i2ml/)__\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9e858",
   "metadata": {},
   "source": [
    "# Exercise sheet 8: CART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b881341c",
   "metadata": {},
   "source": [
    "## Exercise 1: Splitting criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61afb778",
   "metadata": {},
   "source": [
    "Given are the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8aa25",
   "metadata": {},
   "source": [
    "| x | y |\n",
    "| --- | --- |\n",
    "| 1.0 | 1.0 | \n",
    "| 2.0 | 1.0 | \n",
    "| 7.0 | 0.5 | \n",
    "| 10.0 | 10.0 | \n",
    "| 20.0 | 11.0 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0df48c",
   "metadata": {},
   "source": [
    "and the same with log-transformed feature $x$:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854cfced",
   "metadata": {},
   "source": [
    "| log x | y |\n",
    "| --- | --- |\n",
    "| 0.0 | 1.0 | \n",
    "| 0.7 | 1.0 | \n",
    "| 1.9 | 0.5 | \n",
    "| 2.3 | 10.0 | \n",
    "| 3.0 | 11.0 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c337bcb",
   "metadata": {},
   "source": [
    "> a) Compute the first split point the CART algorithm would find for each data set (with pen and paper or in `R`,\n",
    "resp. `Python`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84678745",
   "metadata": {},
   "source": [
    "> b) State the optimal constant predictor for a node $\\mathcal{N}$ when minimizing the empirical risk under $L2$ loss and explain\n",
    "why this is equivalent to minimizing “variance impurity”.\n",
    "\n",
    "> **\\# Entering your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a888ec",
   "metadata": {},
   "source": [
    "## Exercise 2: Impurity reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8900281",
   "metadata": {},
   "source": [
    "The fractions of the classes $k = 1,...,g$ in node $\\mathcal{N}$ of a decision tree are $\\pi_1^{\\mathcal{N}},..., \\pi_g^{\\mathcal{N}}$. Assume we replace the\n",
    "classification rule in node $\\mathcal{N}$\n",
    "$$\n",
    "\\hat{k} | \\mathcal{N} = \\arg\\max_k \\pi_k^{\\mathcal{N}}\n",
    "$$\n",
    "with a randomizing rile\n",
    "$$\n",
    "\\hat{k} \\sim Cat\\left( \\pi_1^{\\mathcal{N}}, ..., \\pi_g^{\\mathcal{N}} \\right)\n",
    "$$,\n",
    "in which we draw the classes in one node from the categorical distribution of their estimated probabilities (i.e.,\n",
    "class $k$ is predicted with probability $\\pi_k^{\\mathcal{N}}$). <br>\n",
    "Compute the expected MCE in node $\\mathcal{N}$ for data distributed i.i.d. like the training data. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8c0dd9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Hint:</b>  The observations and the predictions using the randomizing rule follow the same distribution.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d06012",
   "metadata": {},
   "source": [
    "\n",
    "> **\\# Entering your answer here:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-i2ml",
   "language": "python",
   "name": "python-i2ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
